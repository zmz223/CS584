/home/zzaiman/final_project/unet++
No. of images: 267
/labs/colab/CS584-Spring2021/Lungs-CT/2d_images/ID_0000_Z_0142.tif
/labs/colab/CS584-Spring2021/Lungs-CT/2d_masks/ID_0000_Z_0142.tif
X_train - len/shape: 240 (240, 512, 512, 3)
Y_train is (240, 512, 512, 1), min is 0.0, max is 1.0, mean is 0.2339877764383952
X_test  - len/shape: 27 (27, 512, 512, 1)
(267, 512, 512, 3)
Model: "functional_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, None, None,  0                                            
__________________________________________________________________________________________________
zero_padding2d (ZeroPadding2D)  (None, None, None, 3 0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1/conv (Conv2D)             (None, None, None, 6 9408        zero_padding2d[0][0]             
__________________________________________________________________________________________________
conv1/bn (BatchNormalization)   (None, None, None, 6 256         conv1/conv[0][0]                 
__________________________________________________________________________________________________
conv1/relu (Activation)         (None, None, None, 6 0           conv1/bn[0][0]                   
__________________________________________________________________________________________________
zero_padding2d_1 (ZeroPadding2D (None, None, None, 6 0           conv1/relu[0][0]                 
__________________________________________________________________________________________________
pool1 (MaxPooling2D)            (None, None, None, 6 0           zero_padding2d_1[0][0]           
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, None, None, 6 256         pool1[0][0]                      
__________________________________________________________________________________________________
conv2_block1_0_relu (Activation (None, None, None, 6 0           conv2_block1_0_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, None, None, 1 8192        conv2_block1_0_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, None, None, 1 512         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, None, None, 1 0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, None, None, 3 36864       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_concat (Concatenat (None, None, None, 9 0           pool1[0][0]                      
                                                                 conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_0_bn (BatchNormali (None, None, None, 9 384         conv2_block1_concat[0][0]        
__________________________________________________________________________________________________
conv2_block2_0_relu (Activation (None, None, None, 9 0           conv2_block2_0_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, None, None, 1 12288       conv2_block2_0_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, None, None, 1 512         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, None, None, 1 0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, None, None, 3 36864       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_concat (Concatenat (None, None, None, 1 0           conv2_block1_concat[0][0]        
                                                                 conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_0_bn (BatchNormali (None, None, None, 1 512         conv2_block2_concat[0][0]        
__________________________________________________________________________________________________
conv2_block3_0_relu (Activation (None, None, None, 1 0           conv2_block3_0_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, None, None, 1 16384       conv2_block3_0_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, None, None, 1 512         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, None, None, 1 0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, None, None, 3 36864       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_concat (Concatenat (None, None, None, 1 0           conv2_block2_concat[0][0]        
                                                                 conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block4_0_bn (BatchNormali (None, None, None, 1 640         conv2_block3_concat[0][0]        
__________________________________________________________________________________________________
conv2_block4_0_relu (Activation (None, None, None, 1 0           conv2_block4_0_bn[0][0]          
__________________________________________________________________________________________________
conv2_block4_1_conv (Conv2D)    (None, None, None, 1 20480       conv2_block4_0_relu[0][0]        
__________________________________________________________________________________________________
conv2_block4_1_bn (BatchNormali (None, None, None, 1 512         conv2_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block4_1_relu (Activation (None, None, None, 1 0           conv2_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block4_2_conv (Conv2D)    (None, None, None, 3 36864       conv2_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block4_concat (Concatenat (None, None, None, 1 0           conv2_block3_concat[0][0]        
                                                                 conv2_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block5_0_bn (BatchNormali (None, None, None, 1 768         conv2_block4_concat[0][0]        
__________________________________________________________________________________________________
conv2_block5_0_relu (Activation (None, None, None, 1 0           conv2_block5_0_bn[0][0]          
__________________________________________________________________________________________________
conv2_block5_1_conv (Conv2D)    (None, None, None, 1 24576       conv2_block5_0_relu[0][0]        
__________________________________________________________________________________________________
conv2_block5_1_bn (BatchNormali (None, None, None, 1 512         conv2_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block5_1_relu (Activation (None, None, None, 1 0           conv2_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block5_2_conv (Conv2D)    (None, None, None, 3 36864       conv2_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block5_concat (Concatenat (None, None, None, 2 0           conv2_block4_concat[0][0]        
                                                                 conv2_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block6_0_bn (BatchNormali (None, None, None, 2 896         conv2_block5_concat[0][0]        
__________________________________________________________________________________________________
conv2_block6_0_relu (Activation (None, None, None, 2 0           conv2_block6_0_bn[0][0]          
__________________________________________________________________________________________________
conv2_block6_1_conv (Conv2D)    (None, None, None, 1 28672       conv2_block6_0_relu[0][0]        
__________________________________________________________________________________________________
conv2_block6_1_bn (BatchNormali (None, None, None, 1 512         conv2_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block6_1_relu (Activation (None, None, None, 1 0           conv2_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block6_2_conv (Conv2D)    (None, None, None, 3 36864       conv2_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block6_concat (Concatenat (None, None, None, 2 0           conv2_block5_concat[0][0]        
                                                                 conv2_block6_2_conv[0][0]        
__________________________________________________________________________________________________
pool2_bn (BatchNormalization)   (None, None, None, 2 1024        conv2_block6_concat[0][0]        
__________________________________________________________________________________________________
pool2_relu (Activation)         (None, None, None, 2 0           pool2_bn[0][0]                   
__________________________________________________________________________________________________
pool2_conv (Conv2D)             (None, None, None, 1 32768       pool2_relu[0][0]                 
__________________________________________________________________________________________________
pool2_pool (AveragePooling2D)   (None, None, None, 1 0           pool2_conv[0][0]                 
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, None, None, 1 512         pool2_pool[0][0]                 
__________________________________________________________________________________________________
conv3_block1_0_relu (Activation (None, None, None, 1 0           conv3_block1_0_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, None, None, 1 16384       conv3_block1_0_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, None, None, 1 512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, None, None, 1 0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, None, None, 3 36864       conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_concat (Concatenat (None, None, None, 1 0           pool2_pool[0][0]                 
                                                                 conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_0_bn (BatchNormali (None, None, None, 1 640         conv3_block1_concat[0][0]        
__________________________________________________________________________________________________
conv3_block2_0_relu (Activation (None, None, None, 1 0           conv3_block2_0_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, None, None, 1 20480       conv3_block2_0_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, None, None, 1 512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, None, None, 1 0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, None, None, 3 36864       conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_concat (Concatenat (None, None, None, 1 0           conv3_block1_concat[0][0]        
                                                                 conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_0_bn (BatchNormali (None, None, None, 1 768         conv3_block2_concat[0][0]        
__________________________________________________________________________________________________
conv3_block3_0_relu (Activation (None, None, None, 1 0           conv3_block3_0_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, None, None, 1 24576       conv3_block3_0_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, None, None, 1 512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, None, None, 1 0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, None, None, 3 36864       conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_concat (Concatenat (None, None, None, 2 0           conv3_block2_concat[0][0]        
                                                                 conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_0_bn (BatchNormali (None, None, None, 2 896         conv3_block3_concat[0][0]        
__________________________________________________________________________________________________
conv3_block4_0_relu (Activation (None, None, None, 2 0           conv3_block4_0_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, None, None, 1 28672       conv3_block4_0_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, None, None, 1 512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, None, None, 1 0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, None, None, 3 36864       conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_concat (Concatenat (None, None, None, 2 0           conv3_block3_concat[0][0]        
                                                                 conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block5_0_bn (BatchNormali (None, None, None, 2 1024        conv3_block4_concat[0][0]        
__________________________________________________________________________________________________
conv3_block5_0_relu (Activation (None, None, None, 2 0           conv3_block5_0_bn[0][0]          
__________________________________________________________________________________________________
conv3_block5_1_conv (Conv2D)    (None, None, None, 1 32768       conv3_block5_0_relu[0][0]        
__________________________________________________________________________________________________
conv3_block5_1_bn (BatchNormali (None, None, None, 1 512         conv3_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block5_1_relu (Activation (None, None, None, 1 0           conv3_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block5_2_conv (Conv2D)    (None, None, None, 3 36864       conv3_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block5_concat (Concatenat (None, None, None, 2 0           conv3_block4_concat[0][0]        
                                                                 conv3_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block6_0_bn (BatchNormali (None, None, None, 2 1152        conv3_block5_concat[0][0]        
__________________________________________________________________________________________________
conv3_block6_0_relu (Activation (None, None, None, 2 0           conv3_block6_0_bn[0][0]          
__________________________________________________________________________________________________
conv3_block6_1_conv (Conv2D)    (None, None, None, 1 36864       conv3_block6_0_relu[0][0]        
__________________________________________________________________________________________________
conv3_block6_1_bn (BatchNormali (None, None, None, 1 512         conv3_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block6_1_relu (Activation (None, None, None, 1 0           conv3_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block6_2_conv (Conv2D)    (None, None, None, 3 36864       conv3_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block6_concat (Concatenat (None, None, None, 3 0           conv3_block5_concat[0][0]        
                                                                 conv3_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block7_0_bn (BatchNormali (None, None, None, 3 1280        conv3_block6_concat[0][0]        
__________________________________________________________________________________________________
conv3_block7_0_relu (Activation (None, None, None, 3 0           conv3_block7_0_bn[0][0]          
__________________________________________________________________________________________________
conv3_block7_1_conv (Conv2D)    (None, None, None, 1 40960       conv3_block7_0_relu[0][0]        
__________________________________________________________________________________________________
conv3_block7_1_bn (BatchNormali (None, None, None, 1 512         conv3_block7_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block7_1_relu (Activation (None, None, None, 1 0           conv3_block7_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block7_2_conv (Conv2D)    (None, None, None, 3 36864       conv3_block7_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block7_concat (Concatenat (None, None, None, 3 0           conv3_block6_concat[0][0]        
                                                                 conv3_block7_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block8_0_bn (BatchNormali (None, None, None, 3 1408        conv3_block7_concat[0][0]        
__________________________________________________________________________________________________
conv3_block8_0_relu (Activation (None, None, None, 3 0           conv3_block8_0_bn[0][0]          
__________________________________________________________________________________________________
conv3_block8_1_conv (Conv2D)    (None, None, None, 1 45056       conv3_block8_0_relu[0][0]        
__________________________________________________________________________________________________
conv3_block8_1_bn (BatchNormali (None, None, None, 1 512         conv3_block8_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block8_1_relu (Activation (None, None, None, 1 0           conv3_block8_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block8_2_conv (Conv2D)    (None, None, None, 3 36864       conv3_block8_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block8_concat (Concatenat (None, None, None, 3 0           conv3_block7_concat[0][0]        
                                                                 conv3_block8_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block9_0_bn (BatchNormali (None, None, None, 3 1536        conv3_block8_concat[0][0]        
__________________________________________________________________________________________________
conv3_block9_0_relu (Activation (None, None, None, 3 0           conv3_block9_0_bn[0][0]          
__________________________________________________________________________________________________
conv3_block9_1_conv (Conv2D)    (None, None, None, 1 49152       conv3_block9_0_relu[0][0]        
__________________________________________________________________________________________________
conv3_block9_1_bn (BatchNormali (None, None, None, 1 512         conv3_block9_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block9_1_relu (Activation (None, None, None, 1 0           conv3_block9_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block9_2_conv (Conv2D)    (None, None, None, 3 36864       conv3_block9_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block9_concat (Concatenat (None, None, None, 4 0           conv3_block8_concat[0][0]        
                                                                 conv3_block9_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block10_0_bn (BatchNormal (None, None, None, 4 1664        conv3_block9_concat[0][0]        
__________________________________________________________________________________________________
conv3_block10_0_relu (Activatio (None, None, None, 4 0           conv3_block10_0_bn[0][0]         
__________________________________________________________________________________________________
conv3_block10_1_conv (Conv2D)   (None, None, None, 1 53248       conv3_block10_0_relu[0][0]       
__________________________________________________________________________________________________
conv3_block10_1_bn (BatchNormal (None, None, None, 1 512         conv3_block10_1_conv[0][0]       
__________________________________________________________________________________________________
conv3_block10_1_relu (Activatio (None, None, None, 1 0           conv3_block10_1_bn[0][0]         
__________________________________________________________________________________________________
conv3_block10_2_conv (Conv2D)   (None, None, None, 3 36864       conv3_block10_1_relu[0][0]       
__________________________________________________________________________________________________
conv3_block10_concat (Concatena (None, None, None, 4 0           conv3_block9_concat[0][0]        
                                                                 conv3_block10_2_conv[0][0]       
__________________________________________________________________________________________________
conv3_block11_0_bn (BatchNormal (None, None, None, 4 1792        conv3_block10_concat[0][0]       
__________________________________________________________________________________________________
conv3_block11_0_relu (Activatio (None, None, None, 4 0           conv3_block11_0_bn[0][0]         
__________________________________________________________________________________________________
conv3_block11_1_conv (Conv2D)   (None, None, None, 1 57344       conv3_block11_0_relu[0][0]       
__________________________________________________________________________________________________
conv3_block11_1_bn (BatchNormal (None, None, None, 1 512         conv3_block11_1_conv[0][0]       
__________________________________________________________________________________________________
conv3_block11_1_relu (Activatio (None, None, None, 1 0           conv3_block11_1_bn[0][0]         
__________________________________________________________________________________________________
conv3_block11_2_conv (Conv2D)   (None, None, None, 3 36864       conv3_block11_1_relu[0][0]       
__________________________________________________________________________________________________
conv3_block11_concat (Concatena (None, None, None, 4 0           conv3_block10_concat[0][0]       
                                                                 conv3_block11_2_conv[0][0]       
__________________________________________________________________________________________________
conv3_block12_0_bn (BatchNormal (None, None, None, 4 1920        conv3_block11_concat[0][0]       
__________________________________________________________________________________________________
conv3_block12_0_relu (Activatio (None, None, None, 4 0           conv3_block12_0_bn[0][0]         
__________________________________________________________________________________________________
conv3_block12_1_conv (Conv2D)   (None, None, None, 1 61440       conv3_block12_0_relu[0][0]       
__________________________________________________________________________________________________
conv3_block12_1_bn (BatchNormal (None, None, None, 1 512         conv3_block12_1_conv[0][0]       
__________________________________________________________________________________________________
conv3_block12_1_relu (Activatio (None, None, None, 1 0           conv3_block12_1_bn[0][0]         
__________________________________________________________________________________________________
conv3_block12_2_conv (Conv2D)   (None, None, None, 3 36864       conv3_block12_1_relu[0][0]       
__________________________________________________________________________________________________
conv3_block12_concat (Concatena (None, None, None, 5 0           conv3_block11_concat[0][0]       
                                                                 conv3_block12_2_conv[0][0]       
__________________________________________________________________________________________________
pool3_bn (BatchNormalization)   (None, None, None, 5 2048        conv3_block12_concat[0][0]       
__________________________________________________________________________________________________
pool3_relu (Activation)         (None, None, None, 5 0           pool3_bn[0][0]                   
__________________________________________________________________________________________________
pool3_conv (Conv2D)             (None, None, None, 2 131072      pool3_relu[0][0]                 
__________________________________________________________________________________________________
pool3_pool (AveragePooling2D)   (None, None, None, 2 0           pool3_conv[0][0]                 
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, None, None, 2 1024        pool3_pool[0][0]                 
__________________________________________________________________________________________________
conv4_block1_0_relu (Activation (None, None, None, 2 0           conv4_block1_0_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, None, None, 1 32768       conv4_block1_0_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, None, None, 1 512         conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, None, None, 1 0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, None, None, 3 36864       conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_concat (Concatenat (None, None, None, 2 0           pool3_pool[0][0]                 
                                                                 conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_0_bn (BatchNormali (None, None, None, 2 1152        conv4_block1_concat[0][0]        
__________________________________________________________________________________________________
conv4_block2_0_relu (Activation (None, None, None, 2 0           conv4_block2_0_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, None, None, 1 36864       conv4_block2_0_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, None, None, 1 512         conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, None, None, 1 0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, None, None, 3 36864       conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_concat (Concatenat (None, None, None, 3 0           conv4_block1_concat[0][0]        
                                                                 conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_0_bn (BatchNormali (None, None, None, 3 1280        conv4_block2_concat[0][0]        
__________________________________________________________________________________________________
conv4_block3_0_relu (Activation (None, None, None, 3 0           conv4_block3_0_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, None, None, 1 40960       conv4_block3_0_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, None, None, 1 512         conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, None, None, 1 0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, None, None, 3 36864       conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_concat (Concatenat (None, None, None, 3 0           conv4_block2_concat[0][0]        
                                                                 conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_0_bn (BatchNormali (None, None, None, 3 1408        conv4_block3_concat[0][0]        
__________________________________________________________________________________________________
conv4_block4_0_relu (Activation (None, None, None, 3 0           conv4_block4_0_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, None, None, 1 45056       conv4_block4_0_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, None, None, 1 512         conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, None, None, 1 0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, None, None, 3 36864       conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_concat (Concatenat (None, None, None, 3 0           conv4_block3_concat[0][0]        
                                                                 conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_0_bn (BatchNormali (None, None, None, 3 1536        conv4_block4_concat[0][0]        
__________________________________________________________________________________________________
conv4_block5_0_relu (Activation (None, None, None, 3 0           conv4_block5_0_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, None, None, 1 49152       conv4_block5_0_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, None, None, 1 512         conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, None, None, 1 0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, None, None, 3 36864       conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_concat (Concatenat (None, None, None, 4 0           conv4_block4_concat[0][0]        
                                                                 conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_0_bn (BatchNormali (None, None, None, 4 1664        conv4_block5_concat[0][0]        
__________________________________________________________________________________________________
conv4_block6_0_relu (Activation (None, None, None, 4 0           conv4_block6_0_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, None, None, 1 53248       conv4_block6_0_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, None, None, 1 512         conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, None, None, 1 0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, None, None, 3 36864       conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_concat (Concatenat (None, None, None, 4 0           conv4_block5_concat[0][0]        
                                                                 conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block7_0_bn (BatchNormali (None, None, None, 4 1792        conv4_block6_concat[0][0]        
__________________________________________________________________________________________________
conv4_block7_0_relu (Activation (None, None, None, 4 0           conv4_block7_0_bn[0][0]          
__________________________________________________________________________________________________
conv4_block7_1_conv (Conv2D)    (None, None, None, 1 57344       conv4_block7_0_relu[0][0]        
__________________________________________________________________________________________________
conv4_block7_1_bn (BatchNormali (None, None, None, 1 512         conv4_block7_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block7_1_relu (Activation (None, None, None, 1 0           conv4_block7_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block7_2_conv (Conv2D)    (None, None, None, 3 36864       conv4_block7_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block7_concat (Concatenat (None, None, None, 4 0           conv4_block6_concat[0][0]        
                                                                 conv4_block7_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block8_0_bn (BatchNormali (None, None, None, 4 1920        conv4_block7_concat[0][0]        
__________________________________________________________________________________________________
conv4_block8_0_relu (Activation (None, None, None, 4 0           conv4_block8_0_bn[0][0]          
__________________________________________________________________________________________________
conv4_block8_1_conv (Conv2D)    (None, None, None, 1 61440       conv4_block8_0_relu[0][0]        
__________________________________________________________________________________________________
conv4_block8_1_bn (BatchNormali (None, None, None, 1 512         conv4_block8_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block8_1_relu (Activation (None, None, None, 1 0           conv4_block8_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block8_2_conv (Conv2D)    (None, None, None, 3 36864       conv4_block8_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block8_concat (Concatenat (None, None, None, 5 0           conv4_block7_concat[0][0]        
                                                                 conv4_block8_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block9_0_bn (BatchNormali (None, None, None, 5 2048        conv4_block8_concat[0][0]        
__________________________________________________________________________________________________
conv4_block9_0_relu (Activation (None, None, None, 5 0           conv4_block9_0_bn[0][0]          
__________________________________________________________________________________________________
conv4_block9_1_conv (Conv2D)    (None, None, None, 1 65536       conv4_block9_0_relu[0][0]        
__________________________________________________________________________________________________
conv4_block9_1_bn (BatchNormali (None, None, None, 1 512         conv4_block9_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block9_1_relu (Activation (None, None, None, 1 0           conv4_block9_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block9_2_conv (Conv2D)    (None, None, None, 3 36864       conv4_block9_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block9_concat (Concatenat (None, None, None, 5 0           conv4_block8_concat[0][0]        
                                                                 conv4_block9_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block10_0_bn (BatchNormal (None, None, None, 5 2176        conv4_block9_concat[0][0]        
__________________________________________________________________________________________________
conv4_block10_0_relu (Activatio (None, None, None, 5 0           conv4_block10_0_bn[0][0]         
__________________________________________________________________________________________________
conv4_block10_1_conv (Conv2D)   (None, None, None, 1 69632       conv4_block10_0_relu[0][0]       
__________________________________________________________________________________________________
conv4_block10_1_bn (BatchNormal (None, None, None, 1 512         conv4_block10_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block10_1_relu (Activatio (None, None, None, 1 0           conv4_block10_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block10_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block10_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block10_concat (Concatena (None, None, None, 5 0           conv4_block9_concat[0][0]        
                                                                 conv4_block10_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block11_0_bn (BatchNormal (None, None, None, 5 2304        conv4_block10_concat[0][0]       
__________________________________________________________________________________________________
conv4_block11_0_relu (Activatio (None, None, None, 5 0           conv4_block11_0_bn[0][0]         
__________________________________________________________________________________________________
conv4_block11_1_conv (Conv2D)   (None, None, None, 1 73728       conv4_block11_0_relu[0][0]       
__________________________________________________________________________________________________
conv4_block11_1_bn (BatchNormal (None, None, None, 1 512         conv4_block11_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block11_1_relu (Activatio (None, None, None, 1 0           conv4_block11_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block11_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block11_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block11_concat (Concatena (None, None, None, 6 0           conv4_block10_concat[0][0]       
                                                                 conv4_block11_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block12_0_bn (BatchNormal (None, None, None, 6 2432        conv4_block11_concat[0][0]       
__________________________________________________________________________________________________
conv4_block12_0_relu (Activatio (None, None, None, 6 0           conv4_block12_0_bn[0][0]         
__________________________________________________________________________________________________
conv4_block12_1_conv (Conv2D)   (None, None, None, 1 77824       conv4_block12_0_relu[0][0]       
__________________________________________________________________________________________________
conv4_block12_1_bn (BatchNormal (None, None, None, 1 512         conv4_block12_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block12_1_relu (Activatio (None, None, None, 1 0           conv4_block12_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block12_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block12_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block12_concat (Concatena (None, None, None, 6 0           conv4_block11_concat[0][0]       
                                                                 conv4_block12_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block13_0_bn (BatchNormal (None, None, None, 6 2560        conv4_block12_concat[0][0]       
__________________________________________________________________________________________________
conv4_block13_0_relu (Activatio (None, None, None, 6 0           conv4_block13_0_bn[0][0]         
__________________________________________________________________________________________________
conv4_block13_1_conv (Conv2D)   (None, None, None, 1 81920       conv4_block13_0_relu[0][0]       
__________________________________________________________________________________________________
conv4_block13_1_bn (BatchNormal (None, None, None, 1 512         conv4_block13_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block13_1_relu (Activatio (None, None, None, 1 0           conv4_block13_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block13_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block13_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block13_concat (Concatena (None, None, None, 6 0           conv4_block12_concat[0][0]       
                                                                 conv4_block13_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block14_0_bn (BatchNormal (None, None, None, 6 2688        conv4_block13_concat[0][0]       
__________________________________________________________________________________________________
conv4_block14_0_relu (Activatio (None, None, None, 6 0           conv4_block14_0_bn[0][0]         
__________________________________________________________________________________________________
conv4_block14_1_conv (Conv2D)   (None, None, None, 1 86016       conv4_block14_0_relu[0][0]       
__________________________________________________________________________________________________
conv4_block14_1_bn (BatchNormal (None, None, None, 1 512         conv4_block14_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block14_1_relu (Activatio (None, None, None, 1 0           conv4_block14_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block14_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block14_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block14_concat (Concatena (None, None, None, 7 0           conv4_block13_concat[0][0]       
                                                                 conv4_block14_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block15_0_bn (BatchNormal (None, None, None, 7 2816        conv4_block14_concat[0][0]       
__________________________________________________________________________________________________
conv4_block15_0_relu (Activatio (None, None, None, 7 0           conv4_block15_0_bn[0][0]         
__________________________________________________________________________________________________
conv4_block15_1_conv (Conv2D)   (None, None, None, 1 90112       conv4_block15_0_relu[0][0]       
__________________________________________________________________________________________________
conv4_block15_1_bn (BatchNormal (None, None, None, 1 512         conv4_block15_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block15_1_relu (Activatio (None, None, None, 1 0           conv4_block15_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block15_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block15_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block15_concat (Concatena (None, None, None, 7 0           conv4_block14_concat[0][0]       
                                                                 conv4_block15_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block16_0_bn (BatchNormal (None, None, None, 7 2944        conv4_block15_concat[0][0]       
__________________________________________________________________________________________________
conv4_block16_0_relu (Activatio (None, None, None, 7 0           conv4_block16_0_bn[0][0]         
__________________________________________________________________________________________________
conv4_block16_1_conv (Conv2D)   (None, None, None, 1 94208       conv4_block16_0_relu[0][0]       
__________________________________________________________________________________________________
conv4_block16_1_bn (BatchNormal (None, None, None, 1 512         conv4_block16_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block16_1_relu (Activatio (None, None, None, 1 0           conv4_block16_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block16_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block16_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block16_concat (Concatena (None, None, None, 7 0           conv4_block15_concat[0][0]       
                                                                 conv4_block16_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block17_0_bn (BatchNormal (None, None, None, 7 3072        conv4_block16_concat[0][0]       
__________________________________________________________________________________________________
conv4_block17_0_relu (Activatio (None, None, None, 7 0           conv4_block17_0_bn[0][0]         
__________________________________________________________________________________________________
conv4_block17_1_conv (Conv2D)   (None, None, None, 1 98304       conv4_block17_0_relu[0][0]       
__________________________________________________________________________________________________
conv4_block17_1_bn (BatchNormal (None, None, None, 1 512         conv4_block17_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block17_1_relu (Activatio (None, None, None, 1 0           conv4_block17_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block17_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block17_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block17_concat (Concatena (None, None, None, 8 0           conv4_block16_concat[0][0]       
                                                                 conv4_block17_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block18_0_bn (BatchNormal (None, None, None, 8 3200        conv4_block17_concat[0][0]       
__________________________________________________________________________________________________
conv4_block18_0_relu (Activatio (None, None, None, 8 0           conv4_block18_0_bn[0][0]         
__________________________________________________________________________________________________
conv4_block18_1_conv (Conv2D)   (None, None, None, 1 102400      conv4_block18_0_relu[0][0]       
__________________________________________________________________________________________________
conv4_block18_1_bn (BatchNormal (None, None, None, 1 512         conv4_block18_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block18_1_relu (Activatio (None, None, None, 1 0           conv4_block18_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block18_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block18_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block18_concat (Concatena (None, None, None, 8 0           conv4_block17_concat[0][0]       
                                                                 conv4_block18_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block19_0_bn (BatchNormal (None, None, None, 8 3328        conv4_block18_concat[0][0]       
__________________________________________________________________________________________________
conv4_block19_0_relu (Activatio (None, None, None, 8 0           conv4_block19_0_bn[0][0]         
__________________________________________________________________________________________________
conv4_block19_1_conv (Conv2D)   (None, None, None, 1 106496      conv4_block19_0_relu[0][0]       
__________________________________________________________________________________________________
conv4_block19_1_bn (BatchNormal (None, None, None, 1 512         conv4_block19_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block19_1_relu (Activatio (None, None, None, 1 0           conv4_block19_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block19_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block19_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block19_concat (Concatena (None, None, None, 8 0           conv4_block18_concat[0][0]       
                                                                 conv4_block19_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block20_0_bn (BatchNormal (None, None, None, 8 3456        conv4_block19_concat[0][0]       
__________________________________________________________________________________________________
conv4_block20_0_relu (Activatio (None, None, None, 8 0           conv4_block20_0_bn[0][0]         
__________________________________________________________________________________________________
conv4_block20_1_conv (Conv2D)   (None, None, None, 1 110592      conv4_block20_0_relu[0][0]       
__________________________________________________________________________________________________
conv4_block20_1_bn (BatchNormal (None, None, None, 1 512         conv4_block20_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block20_1_relu (Activatio (None, None, None, 1 0           conv4_block20_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block20_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block20_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block20_concat (Concatena (None, None, None, 8 0           conv4_block19_concat[0][0]       
                                                                 conv4_block20_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block21_0_bn (BatchNormal (None, None, None, 8 3584        conv4_block20_concat[0][0]       
__________________________________________________________________________________________________
conv4_block21_0_relu (Activatio (None, None, None, 8 0           conv4_block21_0_bn[0][0]         
__________________________________________________________________________________________________
conv4_block21_1_conv (Conv2D)   (None, None, None, 1 114688      conv4_block21_0_relu[0][0]       
__________________________________________________________________________________________________
conv4_block21_1_bn (BatchNormal (None, None, None, 1 512         conv4_block21_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block21_1_relu (Activatio (None, None, None, 1 0           conv4_block21_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block21_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block21_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block21_concat (Concatena (None, None, None, 9 0           conv4_block20_concat[0][0]       
                                                                 conv4_block21_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block22_0_bn (BatchNormal (None, None, None, 9 3712        conv4_block21_concat[0][0]       
__________________________________________________________________________________________________
conv4_block22_0_relu (Activatio (None, None, None, 9 0           conv4_block22_0_bn[0][0]         
__________________________________________________________________________________________________
conv4_block22_1_conv (Conv2D)   (None, None, None, 1 118784      conv4_block22_0_relu[0][0]       
__________________________________________________________________________________________________
conv4_block22_1_bn (BatchNormal (None, None, None, 1 512         conv4_block22_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block22_1_relu (Activatio (None, None, None, 1 0           conv4_block22_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block22_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block22_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block22_concat (Concatena (None, None, None, 9 0           conv4_block21_concat[0][0]       
                                                                 conv4_block22_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block23_0_bn (BatchNormal (None, None, None, 9 3840        conv4_block22_concat[0][0]       
__________________________________________________________________________________________________
conv4_block23_0_relu (Activatio (None, None, None, 9 0           conv4_block23_0_bn[0][0]         
__________________________________________________________________________________________________
conv4_block23_1_conv (Conv2D)   (None, None, None, 1 122880      conv4_block23_0_relu[0][0]       
__________________________________________________________________________________________________
conv4_block23_1_bn (BatchNormal (None, None, None, 1 512         conv4_block23_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block23_1_relu (Activatio (None, None, None, 1 0           conv4_block23_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block23_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block23_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block23_concat (Concatena (None, None, None, 9 0           conv4_block22_concat[0][0]       
                                                                 conv4_block23_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block24_0_bn (BatchNormal (None, None, None, 9 3968        conv4_block23_concat[0][0]       
__________________________________________________________________________________________________
conv4_block24_0_relu (Activatio (None, None, None, 9 0           conv4_block24_0_bn[0][0]         
__________________________________________________________________________________________________
conv4_block24_1_conv (Conv2D)   (None, None, None, 1 126976      conv4_block24_0_relu[0][0]       
__________________________________________________________________________________________________
conv4_block24_1_bn (BatchNormal (None, None, None, 1 512         conv4_block24_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block24_1_relu (Activatio (None, None, None, 1 0           conv4_block24_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block24_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block24_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block24_concat (Concatena (None, None, None, 1 0           conv4_block23_concat[0][0]       
                                                                 conv4_block24_2_conv[0][0]       
__________________________________________________________________________________________________
pool4_bn (BatchNormalization)   (None, None, None, 1 4096        conv4_block24_concat[0][0]       
__________________________________________________________________________________________________
pool4_relu (Activation)         (None, None, None, 1 0           pool4_bn[0][0]                   
__________________________________________________________________________________________________
pool4_conv (Conv2D)             (None, None, None, 5 524288      pool4_relu[0][0]                 
__________________________________________________________________________________________________
pool4_pool (AveragePooling2D)   (None, None, None, 5 0           pool4_conv[0][0]                 
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, None, None, 5 2048        pool4_pool[0][0]                 
__________________________________________________________________________________________________
conv5_block1_0_relu (Activation (None, None, None, 5 0           conv5_block1_0_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, None, None, 1 65536       conv5_block1_0_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, None, None, 1 512         conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, None, None, 1 0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, None, None, 3 36864       conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_concat (Concatenat (None, None, None, 5 0           pool4_pool[0][0]                 
                                                                 conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_0_bn (BatchNormali (None, None, None, 5 2176        conv5_block1_concat[0][0]        
__________________________________________________________________________________________________
conv5_block2_0_relu (Activation (None, None, None, 5 0           conv5_block2_0_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, None, None, 1 69632       conv5_block2_0_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, None, None, 1 512         conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, None, None, 1 0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, None, None, 3 36864       conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_concat (Concatenat (None, None, None, 5 0           conv5_block1_concat[0][0]        
                                                                 conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_0_bn (BatchNormali (None, None, None, 5 2304        conv5_block2_concat[0][0]        
__________________________________________________________________________________________________
conv5_block3_0_relu (Activation (None, None, None, 5 0           conv5_block3_0_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, None, None, 1 73728       conv5_block3_0_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, None, None, 1 512         conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, None, None, 1 0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, None, None, 3 36864       conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_concat (Concatenat (None, None, None, 6 0           conv5_block2_concat[0][0]        
                                                                 conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block4_0_bn (BatchNormali (None, None, None, 6 2432        conv5_block3_concat[0][0]        
__________________________________________________________________________________________________
conv5_block4_0_relu (Activation (None, None, None, 6 0           conv5_block4_0_bn[0][0]          
__________________________________________________________________________________________________
conv5_block4_1_conv (Conv2D)    (None, None, None, 1 77824       conv5_block4_0_relu[0][0]        
__________________________________________________________________________________________________
conv5_block4_1_bn (BatchNormali (None, None, None, 1 512         conv5_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block4_1_relu (Activation (None, None, None, 1 0           conv5_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block4_2_conv (Conv2D)    (None, None, None, 3 36864       conv5_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block4_concat (Concatenat (None, None, None, 6 0           conv5_block3_concat[0][0]        
                                                                 conv5_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block5_0_bn (BatchNormali (None, None, None, 6 2560        conv5_block4_concat[0][0]        
__________________________________________________________________________________________________
conv5_block5_0_relu (Activation (None, None, None, 6 0           conv5_block5_0_bn[0][0]          
__________________________________________________________________________________________________
conv5_block5_1_conv (Conv2D)    (None, None, None, 1 81920       conv5_block5_0_relu[0][0]        
__________________________________________________________________________________________________
conv5_block5_1_bn (BatchNormali (None, None, None, 1 512         conv5_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block5_1_relu (Activation (None, None, None, 1 0           conv5_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block5_2_conv (Conv2D)    (None, None, None, 3 36864       conv5_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block5_concat (Concatenat (None, None, None, 6 0           conv5_block4_concat[0][0]        
                                                                 conv5_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block6_0_bn (BatchNormali (None, None, None, 6 2688        conv5_block5_concat[0][0]        
__________________________________________________________________________________________________
conv5_block6_0_relu (Activation (None, None, None, 6 0           conv5_block6_0_bn[0][0]          
__________________________________________________________________________________________________
conv5_block6_1_conv (Conv2D)    (None, None, None, 1 86016       conv5_block6_0_relu[0][0]        
__________________________________________________________________________________________________
conv5_block6_1_bn (BatchNormali (None, None, None, 1 512         conv5_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block6_1_relu (Activation (None, None, None, 1 0           conv5_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block6_2_conv (Conv2D)    (None, None, None, 3 36864       conv5_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block6_concat (Concatenat (None, None, None, 7 0           conv5_block5_concat[0][0]        
                                                                 conv5_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block7_0_bn (BatchNormali (None, None, None, 7 2816        conv5_block6_concat[0][0]        
__________________________________________________________________________________________________
conv5_block7_0_relu (Activation (None, None, None, 7 0           conv5_block7_0_bn[0][0]          
__________________________________________________________________________________________________
conv5_block7_1_conv (Conv2D)    (None, None, None, 1 90112       conv5_block7_0_relu[0][0]        
__________________________________________________________________________________________________
conv5_block7_1_bn (BatchNormali (None, None, None, 1 512         conv5_block7_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block7_1_relu (Activation (None, None, None, 1 0           conv5_block7_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block7_2_conv (Conv2D)    (None, None, None, 3 36864       conv5_block7_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block7_concat (Concatenat (None, None, None, 7 0           conv5_block6_concat[0][0]        
                                                                 conv5_block7_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block8_0_bn (BatchNormali (None, None, None, 7 2944        conv5_block7_concat[0][0]        
__________________________________________________________________________________________________
conv5_block8_0_relu (Activation (None, None, None, 7 0           conv5_block8_0_bn[0][0]          
__________________________________________________________________________________________________
conv5_block8_1_conv (Conv2D)    (None, None, None, 1 94208       conv5_block8_0_relu[0][0]        
__________________________________________________________________________________________________
conv5_block8_1_bn (BatchNormali (None, None, None, 1 512         conv5_block8_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block8_1_relu (Activation (None, None, None, 1 0           conv5_block8_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block8_2_conv (Conv2D)    (None, None, None, 3 36864       conv5_block8_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block8_concat (Concatenat (None, None, None, 7 0           conv5_block7_concat[0][0]        
                                                                 conv5_block8_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block9_0_bn (BatchNormali (None, None, None, 7 3072        conv5_block8_concat[0][0]        
__________________________________________________________________________________________________
conv5_block9_0_relu (Activation (None, None, None, 7 0           conv5_block9_0_bn[0][0]          
__________________________________________________________________________________________________
conv5_block9_1_conv (Conv2D)    (None, None, None, 1 98304       conv5_block9_0_relu[0][0]        
__________________________________________________________________________________________________
conv5_block9_1_bn (BatchNormali (None, None, None, 1 512         conv5_block9_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block9_1_relu (Activation (None, None, None, 1 0           conv5_block9_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block9_2_conv (Conv2D)    (None, None, None, 3 36864       conv5_block9_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block9_concat (Concatenat (None, None, None, 8 0           conv5_block8_concat[0][0]        
                                                                 conv5_block9_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block10_0_bn (BatchNormal (None, None, None, 8 3200        conv5_block9_concat[0][0]        
__________________________________________________________________________________________________
conv5_block10_0_relu (Activatio (None, None, None, 8 0           conv5_block10_0_bn[0][0]         
__________________________________________________________________________________________________
conv5_block10_1_conv (Conv2D)   (None, None, None, 1 102400      conv5_block10_0_relu[0][0]       
__________________________________________________________________________________________________
conv5_block10_1_bn (BatchNormal (None, None, None, 1 512         conv5_block10_1_conv[0][0]       
__________________________________________________________________________________________________
conv5_block10_1_relu (Activatio (None, None, None, 1 0           conv5_block10_1_bn[0][0]         
__________________________________________________________________________________________________
conv5_block10_2_conv (Conv2D)   (None, None, None, 3 36864       conv5_block10_1_relu[0][0]       
__________________________________________________________________________________________________
conv5_block10_concat (Concatena (None, None, None, 8 0           conv5_block9_concat[0][0]        
                                                                 conv5_block10_2_conv[0][0]       
__________________________________________________________________________________________________
conv5_block11_0_bn (BatchNormal (None, None, None, 8 3328        conv5_block10_concat[0][0]       
__________________________________________________________________________________________________
conv5_block11_0_relu (Activatio (None, None, None, 8 0           conv5_block11_0_bn[0][0]         
__________________________________________________________________________________________________
conv5_block11_1_conv (Conv2D)   (None, None, None, 1 106496      conv5_block11_0_relu[0][0]       
__________________________________________________________________________________________________
conv5_block11_1_bn (BatchNormal (None, None, None, 1 512         conv5_block11_1_conv[0][0]       
__________________________________________________________________________________________________
conv5_block11_1_relu (Activatio (None, None, None, 1 0           conv5_block11_1_bn[0][0]         
__________________________________________________________________________________________________
conv5_block11_2_conv (Conv2D)   (None, None, None, 3 36864       conv5_block11_1_relu[0][0]       
__________________________________________________________________________________________________
conv5_block11_concat (Concatena (None, None, None, 8 0           conv5_block10_concat[0][0]       
                                                                 conv5_block11_2_conv[0][0]       
__________________________________________________________________________________________________
conv5_block12_0_bn (BatchNormal (None, None, None, 8 3456        conv5_block11_concat[0][0]       
__________________________________________________________________________________________________
conv5_block12_0_relu (Activatio (None, None, None, 8 0           conv5_block12_0_bn[0][0]         
__________________________________________________________________________________________________
conv5_block12_1_conv (Conv2D)   (None, None, None, 1 110592      conv5_block12_0_relu[0][0]       
__________________________________________________________________________________________________
conv5_block12_1_bn (BatchNormal (None, None, None, 1 512         conv5_block12_1_conv[0][0]       
__________________________________________________________________________________________________
conv5_block12_1_relu (Activatio (None, None, None, 1 0           conv5_block12_1_bn[0][0]         
__________________________________________________________________________________________________
conv5_block12_2_conv (Conv2D)   (None, None, None, 3 36864       conv5_block12_1_relu[0][0]       
__________________________________________________________________________________________________
conv5_block12_concat (Concatena (None, None, None, 8 0           conv5_block11_concat[0][0]       
                                                                 conv5_block12_2_conv[0][0]       
__________________________________________________________________________________________________
conv5_block13_0_bn (BatchNormal (None, None, None, 8 3584        conv5_block12_concat[0][0]       
__________________________________________________________________________________________________
conv5_block13_0_relu (Activatio (None, None, None, 8 0           conv5_block13_0_bn[0][0]         
__________________________________________________________________________________________________
conv5_block13_1_conv (Conv2D)   (None, None, None, 1 114688      conv5_block13_0_relu[0][0]       
__________________________________________________________________________________________________
conv5_block13_1_bn (BatchNormal (None, None, None, 1 512         conv5_block13_1_conv[0][0]       
__________________________________________________________________________________________________
conv5_block13_1_relu (Activatio (None, None, None, 1 0           conv5_block13_1_bn[0][0]         
__________________________________________________________________________________________________
conv5_block13_2_conv (Conv2D)   (None, None, None, 3 36864       conv5_block13_1_relu[0][0]       
__________________________________________________________________________________________________
conv5_block13_concat (Concatena (None, None, None, 9 0           conv5_block12_concat[0][0]       
                                                                 conv5_block13_2_conv[0][0]       
__________________________________________________________________________________________________
conv5_block14_0_bn (BatchNormal (None, None, None, 9 3712        conv5_block13_concat[0][0]       
__________________________________________________________________________________________________
conv5_block14_0_relu (Activatio (None, None, None, 9 0           conv5_block14_0_bn[0][0]         
__________________________________________________________________________________________________
conv5_block14_1_conv (Conv2D)   (None, None, None, 1 118784      conv5_block14_0_relu[0][0]       
__________________________________________________________________________________________________
conv5_block14_1_bn (BatchNormal (None, None, None, 1 512         conv5_block14_1_conv[0][0]       
__________________________________________________________________________________________________
conv5_block14_1_relu (Activatio (None, None, None, 1 0           conv5_block14_1_bn[0][0]         
__________________________________________________________________________________________________
conv5_block14_2_conv (Conv2D)   (None, None, None, 3 36864       conv5_block14_1_relu[0][0]       
__________________________________________________________________________________________________
conv5_block14_concat (Concatena (None, None, None, 9 0           conv5_block13_concat[0][0]       
                                                                 conv5_block14_2_conv[0][0]       
__________________________________________________________________________________________________
conv5_block15_0_bn (BatchNormal (None, None, None, 9 3840        conv5_block14_concat[0][0]       
__________________________________________________________________________________________________
conv5_block15_0_relu (Activatio (None, None, None, 9 0           conv5_block15_0_bn[0][0]         
__________________________________________________________________________________________________
conv5_block15_1_conv (Conv2D)   (None, None, None, 1 122880      conv5_block15_0_relu[0][0]       
__________________________________________________________________________________________________
conv5_block15_1_bn (BatchNormal (None, None, None, 1 512         conv5_block15_1_conv[0][0]       
__________________________________________________________________________________________________
conv5_block15_1_relu (Activatio (None, None, None, 1 0           conv5_block15_1_bn[0][0]         
__________________________________________________________________________________________________
conv5_block15_2_conv (Conv2D)   (None, None, None, 3 36864       conv5_block15_1_relu[0][0]       
__________________________________________________________________________________________________
conv5_block15_concat (Concatena (None, None, None, 9 0           conv5_block14_concat[0][0]       
                                                                 conv5_block15_2_conv[0][0]       
__________________________________________________________________________________________________
conv5_block16_0_bn (BatchNormal (None, None, None, 9 3968        conv5_block15_concat[0][0]       
__________________________________________________________________________________________________
conv5_block16_0_relu (Activatio (None, None, None, 9 0           conv5_block16_0_bn[0][0]         
__________________________________________________________________________________________________
conv5_block16_1_conv (Conv2D)   (None, None, None, 1 126976      conv5_block16_0_relu[0][0]       
__________________________________________________________________________________________________
conv5_block16_1_bn (BatchNormal (None, None, None, 1 512         conv5_block16_1_conv[0][0]       
__________________________________________________________________________________________________
conv5_block16_1_relu (Activatio (None, None, None, 1 0           conv5_block16_1_bn[0][0]         
__________________________________________________________________________________________________
conv5_block16_2_conv (Conv2D)   (None, None, None, 3 36864       conv5_block16_1_relu[0][0]       
__________________________________________________________________________________________________
conv5_block16_concat (Concatena (None, None, None, 1 0           conv5_block15_concat[0][0]       
                                                                 conv5_block16_2_conv[0][0]       
__________________________________________________________________________________________________
bn (BatchNormalization)         (None, None, None, 1 4096        conv5_block16_concat[0][0]       
__________________________________________________________________________________________________
relu (Activation)               (None, None, None, 1 0           bn[0][0]                         
__________________________________________________________________________________________________
decoder_stage5-1_upsample (Conv (None, None, None, 1 262144      relu[0][0]                       
__________________________________________________________________________________________________
decoder_stage5-1_bn1 (BatchNorm (None, None, None, 1 64          decoder_stage5-1_upsample[0][0]  
__________________________________________________________________________________________________
decoder_stage5-1_relu1 (Activat (None, None, None, 1 0           decoder_stage5-1_bn1[0][0]       
__________________________________________________________________________________________________
merge_5-1 (Concatenate)         (None, None, None, 5 0           decoder_stage5-1_relu1[0][0]     
                                                                 pool4_conv[0][0]                 
__________________________________________________________________________________________________
decoder_stage4-1_upsample (Conv (None, None, None, 2 2097152     pool4_conv[0][0]                 
__________________________________________________________________________________________________
decoder_stage5-1_conv2 (Conv2D) (None, None, None, 1 76032       merge_5-1[0][0]                  
__________________________________________________________________________________________________
decoder_stage4-1_bn1 (BatchNorm (None, None, None, 2 1024        decoder_stage4-1_upsample[0][0]  
__________________________________________________________________________________________________
decoder_stage5-1_bn2 (BatchNorm (None, None, None, 1 64          decoder_stage5-1_conv2[0][0]     
__________________________________________________________________________________________________
decoder_stage4-1_relu1 (Activat (None, None, None, 2 0           decoder_stage4-1_bn1[0][0]       
__________________________________________________________________________________________________
decoder_stage5-1_relu2 (Activat (None, None, None, 1 0           decoder_stage5-1_bn2[0][0]       
__________________________________________________________________________________________________
merge_4-1 (Concatenate)         (None, None, None, 5 0           decoder_stage4-1_relu1[0][0]     
                                                                 pool3_conv[0][0]                 
__________________________________________________________________________________________________
decoder_stage3-1_upsample (Conv (None, None, None, 1 524288      pool3_conv[0][0]                 
__________________________________________________________________________________________________
decoder_stage4-2_upsample (Conv (None, None, None, 2 65536       decoder_stage5-1_relu2[0][0]     
__________________________________________________________________________________________________
decoder_stage4-1_conv2 (Conv2D) (None, None, None, 2 1179648     merge_4-1[0][0]                  
__________________________________________________________________________________________________
decoder_stage3-1_bn1 (BatchNorm (None, None, None, 1 512         decoder_stage3-1_upsample[0][0]  
__________________________________________________________________________________________________
decoder_stage4-2_bn1 (BatchNorm (None, None, None, 2 1024        decoder_stage4-2_upsample[0][0]  
__________________________________________________________________________________________________
decoder_stage4-1_bn2 (BatchNorm (None, None, None, 2 1024        decoder_stage4-1_conv2[0][0]     
__________________________________________________________________________________________________
decoder_stage3-1_relu1 (Activat (None, None, None, 1 0           decoder_stage3-1_bn1[0][0]       
__________________________________________________________________________________________________
decoder_stage4-2_relu1 (Activat (None, None, None, 2 0           decoder_stage4-2_bn1[0][0]       
__________________________________________________________________________________________________
decoder_stage4-1_relu2 (Activat (None, None, None, 2 0           decoder_stage4-1_bn2[0][0]       
__________________________________________________________________________________________________
merge_3-1 (Concatenate)         (None, None, None, 2 0           decoder_stage3-1_relu1[0][0]     
                                                                 pool2_conv[0][0]                 
__________________________________________________________________________________________________
decoder_stage2-1_upsample (Conv (None, None, None, 6 131072      pool2_conv[0][0]                 
__________________________________________________________________________________________________
merge_4-2 (Concatenate)         (None, None, None, 7 0           decoder_stage4-2_relu1[0][0]     
                                                                 pool3_conv[0][0]                 
                                                                 decoder_stage4-1_relu2[0][0]     
__________________________________________________________________________________________________
decoder_stage3-1_conv2 (Conv2D) (None, None, None, 1 294912      merge_3-1[0][0]                  
__________________________________________________________________________________________________
decoder_stage3-2_upsample (Conv (None, None, None, 1 524288      decoder_stage4-1_relu2[0][0]     
__________________________________________________________________________________________________
decoder_stage2-1_bn1 (BatchNorm (None, None, None, 6 256         decoder_stage2-1_upsample[0][0]  
__________________________________________________________________________________________________
decoder_stage4-2_conv2 (Conv2D) (None, None, None, 2 1769472     merge_4-2[0][0]                  
__________________________________________________________________________________________________
decoder_stage3-1_bn2 (BatchNorm (None, None, None, 1 512         decoder_stage3-1_conv2[0][0]     
__________________________________________________________________________________________________
decoder_stage3-2_bn1 (BatchNorm (None, None, None, 1 512         decoder_stage3-2_upsample[0][0]  
__________________________________________________________________________________________________
decoder_stage2-1_relu1 (Activat (None, None, None, 6 0           decoder_stage2-1_bn1[0][0]       
__________________________________________________________________________________________________
decoder_stage4-2_bn2 (BatchNorm (None, None, None, 2 1024        decoder_stage4-2_conv2[0][0]     
__________________________________________________________________________________________________
decoder_stage3-1_relu2 (Activat (None, None, None, 1 0           decoder_stage3-1_bn2[0][0]       
__________________________________________________________________________________________________
decoder_stage3-2_relu1 (Activat (None, None, None, 1 0           decoder_stage3-2_bn1[0][0]       
__________________________________________________________________________________________________
merge_2-1 (Concatenate)         (None, None, None, 1 0           decoder_stage2-1_relu1[0][0]     
                                                                 conv1/relu[0][0]                 
__________________________________________________________________________________________________
decoder_stage4-2_relu2 (Activat (None, None, None, 2 0           decoder_stage4-2_bn2[0][0]       
__________________________________________________________________________________________________
merge_3-2 (Concatenate)         (None, None, None, 3 0           decoder_stage3-2_relu1[0][0]     
                                                                 pool2_conv[0][0]                 
                                                                 decoder_stage3-1_relu2[0][0]     
__________________________________________________________________________________________________
decoder_stage2-1_conv2 (Conv2D) (None, None, None, 6 73728       merge_2-1[0][0]                  
__________________________________________________________________________________________________
decoder_stage2-2_upsample (Conv (None, None, None, 6 131072      decoder_stage3-1_relu2[0][0]     
__________________________________________________________________________________________________
decoder_stage3-3_upsample (Conv (None, None, None, 1 524288      decoder_stage4-2_relu2[0][0]     
__________________________________________________________________________________________________
decoder_stage3-2_conv2 (Conv2D) (None, None, None, 1 442368      merge_3-2[0][0]                  
__________________________________________________________________________________________________
decoder_stage2-1_bn2 (BatchNorm (None, None, None, 6 256         decoder_stage2-1_conv2[0][0]     
__________________________________________________________________________________________________
decoder_stage2-2_bn1 (BatchNorm (None, None, None, 6 256         decoder_stage2-2_upsample[0][0]  
__________________________________________________________________________________________________
decoder_stage3-3_bn1 (BatchNorm (None, None, None, 1 512         decoder_stage3-3_upsample[0][0]  
__________________________________________________________________________________________________
decoder_stage3-2_bn2 (BatchNorm (None, None, None, 1 512         decoder_stage3-2_conv2[0][0]     
__________________________________________________________________________________________________
decoder_stage2-1_relu2 (Activat (None, None, None, 6 0           decoder_stage2-1_bn2[0][0]       
__________________________________________________________________________________________________
decoder_stage2-2_relu1 (Activat (None, None, None, 6 0           decoder_stage2-2_bn1[0][0]       
__________________________________________________________________________________________________
decoder_stage3-3_relu1 (Activat (None, None, None, 1 0           decoder_stage3-3_bn1[0][0]       
__________________________________________________________________________________________________
decoder_stage3-2_relu2 (Activat (None, None, None, 1 0           decoder_stage3-2_bn2[0][0]       
__________________________________________________________________________________________________
merge_2-2 (Concatenate)         (None, None, None, 1 0           decoder_stage2-2_relu1[0][0]     
                                                                 conv1/relu[0][0]                 
                                                                 decoder_stage2-1_relu2[0][0]     
__________________________________________________________________________________________________
merge_3-3 (Concatenate)         (None, None, None, 5 0           decoder_stage3-3_relu1[0][0]     
                                                                 pool2_conv[0][0]                 
                                                                 decoder_stage3-1_relu2[0][0]     
                                                                 decoder_stage3-2_relu2[0][0]     
__________________________________________________________________________________________________
decoder_stage2-2_conv2 (Conv2D) (None, None, None, 6 110592      merge_2-2[0][0]                  
__________________________________________________________________________________________________
decoder_stage2-3_upsample (Conv (None, None, None, 6 131072      decoder_stage3-2_relu2[0][0]     
__________________________________________________________________________________________________
decoder_stage3-3_conv2 (Conv2D) (None, None, None, 1 589824      merge_3-3[0][0]                  
__________________________________________________________________________________________________
decoder_stage2-2_bn2 (BatchNorm (None, None, None, 6 256         decoder_stage2-2_conv2[0][0]     
__________________________________________________________________________________________________
decoder_stage2-3_bn1 (BatchNorm (None, None, None, 6 256         decoder_stage2-3_upsample[0][0]  
__________________________________________________________________________________________________
decoder_stage3-3_bn2 (BatchNorm (None, None, None, 1 512         decoder_stage3-3_conv2[0][0]     
__________________________________________________________________________________________________
decoder_stage2-2_relu2 (Activat (None, None, None, 6 0           decoder_stage2-2_bn2[0][0]       
__________________________________________________________________________________________________
decoder_stage2-3_relu1 (Activat (None, None, None, 6 0           decoder_stage2-3_bn1[0][0]       
__________________________________________________________________________________________________
decoder_stage3-3_relu2 (Activat (None, None, None, 1 0           decoder_stage3-3_bn2[0][0]       
__________________________________________________________________________________________________
merge_2-3 (Concatenate)         (None, None, None, 2 0           decoder_stage2-3_relu1[0][0]     
                                                                 conv1/relu[0][0]                 
                                                                 decoder_stage2-1_relu2[0][0]     
                                                                 decoder_stage2-2_relu2[0][0]     
__________________________________________________________________________________________________
decoder_stage2-4_upsample (Conv (None, None, None, 6 131072      decoder_stage3-3_relu2[0][0]     
__________________________________________________________________________________________________
decoder_stage2-3_conv2 (Conv2D) (None, None, None, 6 147456      merge_2-3[0][0]                  
__________________________________________________________________________________________________
decoder_stage2-4_bn1 (BatchNorm (None, None, None, 6 256         decoder_stage2-4_upsample[0][0]  
__________________________________________________________________________________________________
decoder_stage2-3_bn2 (BatchNorm (None, None, None, 6 256         decoder_stage2-3_conv2[0][0]     
__________________________________________________________________________________________________
decoder_stage2-4_relu1 (Activat (None, None, None, 6 0           decoder_stage2-4_bn1[0][0]       
__________________________________________________________________________________________________
decoder_stage2-3_relu2 (Activat (None, None, None, 6 0           decoder_stage2-3_bn2[0][0]       
__________________________________________________________________________________________________
merge_2-4 (Concatenate)         (None, None, None, 3 0           decoder_stage2-4_relu1[0][0]     
                                                                 conv1/relu[0][0]                 
                                                                 decoder_stage2-1_relu2[0][0]     
                                                                 decoder_stage2-2_relu2[0][0]     
                                                                 decoder_stage2-3_relu2[0][0]     
__________________________________________________________________________________________________
decoder_stage2-4_conv2 (Conv2D) (None, None, None, 6 184320      merge_2-4[0][0]                  
__________________________________________________________________________________________________
decoder_stage2-4_bn2 (BatchNorm (None, None, None, 6 256         decoder_stage2-4_conv2[0][0]     
__________________________________________________________________________________________________
decoder_stage2-4_relu2 (Activat (None, None, None, 6 0           decoder_stage2-4_bn2[0][0]       
__________________________________________________________________________________________________
decoder_stage1-5_upsample (Conv (None, None, None, 3 32768       decoder_stage2-4_relu2[0][0]     
__________________________________________________________________________________________________
decoder_stage1-5_bn1 (BatchNorm (None, None, None, 3 128         decoder_stage1-5_upsample[0][0]  
__________________________________________________________________________________________________
decoder_stage1-5_relu1 (Activat (None, None, None, 3 0           decoder_stage1-5_bn1[0][0]       
__________________________________________________________________________________________________
decoder_stage1-5_conv2 (Conv2D) (None, None, None, 3 9216        decoder_stage1-5_relu1[0][0]     
__________________________________________________________________________________________________
decoder_stage1-5_bn2 (BatchNorm (None, None, None, 3 128         decoder_stage1-5_conv2[0][0]     
__________________________________________________________________________________________________
decoder_stage1-5_relu2 (Activat (None, None, None, 3 0           decoder_stage1-5_bn2[0][0]       
__________________________________________________________________________________________________
final_conv (Conv2D)             (None, None, None, 1 289         decoder_stage1-5_relu2[0][0]     
__________________________________________________________________________________________________
sigmoid (Activation)            (None, None, None, 1 0           final_conv[0][0]                 
==================================================================================================
Total params: 16,479,713
Trainable params: 16,391,265
Non-trainable params: 88,448
__________________________________________________________________________________________________
Train on 240 samples, validate on 27 samples
Epoch 1/50
 10/240 [>.............................] - ETA: 0s - loss: 0.6906 - accuracy: 0.5839 20/240 [=>............................] - ETA: 9s - loss: 0.6603 - accuracy: 0.6078 30/240 [==>...........................] - ETA: 11s - loss: 0.6091 - accuracy: 0.6557 40/240 [====>.........................] - ETA: 12s - loss: 0.5561 - accuracy: 0.7050 50/240 [=====>........................] - ETA: 12s - loss: 0.5066 - accuracy: 0.7522 60/240 [======>.......................] - ETA: 12s - loss: 0.4682 - accuracy: 0.7832 70/240 [=======>......................] - ETA: 12s - loss: 0.4389 - accuracy: 0.8021 80/240 [=========>....................] - ETA: 11s - loss: 0.4022 - accuracy: 0.8247 90/240 [==========>...................] - ETA: 11s - loss: 0.3744 - accuracy: 0.8410100/240 [===========>..................] - ETA: 10s - loss: 0.3527 - accuracy: 0.8535110/240 [============>.................] - ETA: 9s - loss: 0.3288 - accuracy: 0.8658 120/240 [==============>...............] - ETA: 9s - loss: 0.3120 - accuracy: 0.8745130/240 [===============>..............] - ETA: 8s - loss: 0.2938 - accuracy: 0.8833140/240 [================>.............] - ETA: 7s - loss: 0.2778 - accuracy: 0.8909150/240 [=================>............] - ETA: 7s - loss: 0.2670 - accuracy: 0.8964160/240 [===================>..........] - ETA: 6s - loss: 0.2544 - accuracy: 0.9020170/240 [====================>.........] - ETA: 5s - loss: 0.2428 - accuracy: 0.9072180/240 [=====================>........] - ETA: 4s - loss: 0.2323 - accuracy: 0.9118190/240 [======================>.......] - ETA: 3s - loss: 0.2230 - accuracy: 0.9158200/240 [========================>.....] - ETA: 3s - loss: 0.2145 - accuracy: 0.9195210/240 [=========================>....] - ETA: 2s - loss: 0.2064 - accuracy: 0.9229220/240 [==========================>...] - ETA: 1s - loss: 0.1991 - accuracy: 0.9260230/240 [===========================>..] - ETA: 0s - loss: 0.1923 - accuracy: 0.9288240/240 [==============================] - ETA: 0s - loss: 0.1863 - accuracy: 0.9313
Epoch 00001: val_loss improved from inf to 3.77090, saving model to model-lung.hdf5
240/240 [==============================] - 178s 742ms/sample - loss: 0.1863 - accuracy: 0.9313 - val_loss: 3.7709 - val_accuracy: 0.7533
Epoch 2/50
 10/240 [>.............................] - ETA: 0s - loss: 0.1971 - accuracy: 0.9546 20/240 [=>............................] - ETA: 9s - loss: 0.1168 - accuracy: 0.9735 30/240 [==>...........................] - ETA: 11s - loss: 0.0902 - accuracy: 0.9798 40/240 [====>.........................] - ETA: 12s - loss: 0.0771 - accuracy: 0.9828 50/240 [=====>........................] - ETA: 12s - loss: 0.0684 - accuracy: 0.9849 60/240 [======>.......................] - ETA: 12s - loss: 0.0628 - accuracy: 0.9861 70/240 [=======>......................] - ETA: 12s - loss: 0.0685 - accuracy: 0.9846 80/240 [=========>....................] - ETA: 11s - loss: 0.0645 - accuracy: 0.9855 90/240 [==========>...................] - ETA: 11s - loss: 0.0615 - accuracy: 0.9861100/240 [===========>..................] - ETA: 10s - loss: 0.0582 - accuracy: 0.9869110/240 [============>.................] - ETA: 9s - loss: 0.0557 - accuracy: 0.9875 120/240 [==============>...............] - ETA: 9s - loss: 0.0539 - accuracy: 0.9879130/240 [===============>..............] - ETA: 8s - loss: 0.0526 - accuracy: 0.9881140/240 [================>.............] - ETA: 7s - loss: 0.0508 - accuracy: 0.9885150/240 [=================>............] - ETA: 7s - loss: 0.0492 - accuracy: 0.9889160/240 [===================>..........] - ETA: 6s - loss: 0.0555 - accuracy: 0.9873170/240 [====================>.........] - ETA: 5s - loss: 0.0540 - accuracy: 0.9877180/240 [=====================>........] - ETA: 4s - loss: 0.0529 - accuracy: 0.9878190/240 [======================>.......] - ETA: 3s - loss: 0.0516 - accuracy: 0.9881200/240 [========================>.....] - ETA: 3s - loss: 0.0502 - accuracy: 0.9884210/240 [=========================>....] - ETA: 2s - loss: 0.0491 - accuracy: 0.9886220/240 [==========================>...] - ETA: 1s - loss: 0.0482 - accuracy: 0.9888230/240 [===========================>..] - ETA: 0s - loss: 0.0473 - accuracy: 0.9890240/240 [==============================] - ETA: 0s - loss: 0.0464 - accuracy: 0.9891
Epoch 00002: val_loss improved from 3.77090 to 1.20663, saving model to model-lung.hdf5
240/240 [==============================] - 24s 98ms/sample - loss: 0.0464 - accuracy: 0.9891 - val_loss: 1.2066 - val_accuracy: 0.7533
Epoch 3/50
 10/240 [>.............................] - ETA: 0s - loss: 0.0260 - accuracy: 0.9924 20/240 [=>............................] - ETA: 9s - loss: 0.0247 - accuracy: 0.9932 30/240 [==>...........................] - ETA: 11s - loss: 0.0244 - accuracy: 0.9931 40/240 [====>.........................] - ETA: 12s - loss: 0.0240 - accuracy: 0.9932 50/240 [=====>........................] - ETA: 12s - loss: 0.0248 - accuracy: 0.9931 60/240 [======>.......................] - ETA: 12s - loss: 0.0248 - accuracy: 0.9930 70/240 [=======>......................] - ETA: 12s - loss: 0.0248 - accuracy: 0.9930 80/240 [=========>....................] - ETA: 11s - loss: 0.0352 - accuracy: 0.9910 90/240 [==========>...................] - ETA: 11s - loss: 0.0341 - accuracy: 0.9912100/240 [===========>..................] - ETA: 10s - loss: 0.0328 - accuracy: 0.9916110/240 [============>.................] - ETA: 10s - loss: 0.0317 - accuracy: 0.9919120/240 [==============>...............] - ETA: 9s - loss: 0.0311 - accuracy: 0.9919 130/240 [===============>..............] - ETA: 8s - loss: 0.0304 - accuracy: 0.9920140/240 [================>.............] - ETA: 7s - loss: 0.0295 - accuracy: 0.9923150/240 [=================>............] - ETA: 7s - loss: 0.0292 - accuracy: 0.9923160/240 [===================>..........] - ETA: 6s - loss: 0.0287 - accuracy: 0.9924170/240 [====================>.........] - ETA: 5s - loss: 0.0395 - accuracy: 0.9902180/240 [=====================>........] - ETA: 4s - loss: 0.0384 - accuracy: 0.9905190/240 [======================>.......] - ETA: 4s - loss: 0.0375 - accuracy: 0.9907200/240 [========================>.....] - ETA: 3s - loss: 0.0398 - accuracy: 0.9900210/240 [=========================>....] - ETA: 2s - loss: 0.0428 - accuracy: 0.9894220/240 [==========================>...] - ETA: 1s - loss: 0.0423 - accuracy: 0.9897230/240 [===========================>..] - ETA: 0s - loss: 0.0416 - accuracy: 0.9898240/240 [==============================] - ETA: 0s - loss: 0.0407 - accuracy: 0.9901
Epoch 00003: val_loss improved from 1.20663 to 0.53322, saving model to model-lung.hdf5
240/240 [==============================] - 24s 99ms/sample - loss: 0.0407 - accuracy: 0.9901 - val_loss: 0.5332 - val_accuracy: 0.7841
Epoch 4/50
 10/240 [>.............................] - ETA: 0s - loss: 0.0226 - accuracy: 0.9947 20/240 [=>............................] - ETA: 9s - loss: 0.0213 - accuracy: 0.9949 30/240 [==>...........................] - ETA: 11s - loss: 0.0217 - accuracy: 0.9945 40/240 [====>.........................] - ETA: 12s - loss: 0.0223 - accuracy: 0.9940 50/240 [=====>........................] - ETA: 12s - loss: 0.0223 - accuracy: 0.9940 60/240 [======>.......................] - ETA: 12s - loss: 0.0219 - accuracy: 0.9941 70/240 [=======>......................] - ETA: 12s - loss: 0.0220 - accuracy: 0.9938 80/240 [=========>....................] - ETA: 11s - loss: 0.0216 - accuracy: 0.9939 90/240 [==========>...................] - ETA: 11s - loss: 0.0238 - accuracy: 0.9929100/240 [===========>..................] - ETA: 10s - loss: 0.0232 - accuracy: 0.9932110/240 [============>.................] - ETA: 10s - loss: 0.0262 - accuracy: 0.9924120/240 [==============>...............] - ETA: 9s - loss: 0.0268 - accuracy: 0.9920 130/240 [===============>..............] - ETA: 8s - loss: 0.0267 - accuracy: 0.9919140/240 [================>.............] - ETA: 7s - loss: 0.0339 - accuracy: 0.9902150/240 [=================>............] - ETA: 7s - loss: 0.0392 - accuracy: 0.9890160/240 [===================>..........] - ETA: 6s - loss: 0.0385 - accuracy: 0.9892170/240 [====================>.........] - ETA: 5s - loss: 0.0389 - accuracy: 0.9890180/240 [=====================>........] - ETA: 4s - loss: 0.0547 - accuracy: 0.9859190/240 [======================>.......] - ETA: 4s - loss: 0.0536 - accuracy: 0.9860200/240 [========================>.....] - ETA: 3s - loss: 0.0521 - accuracy: 0.9864210/240 [=========================>....] - ETA: 2s - loss: 0.0512 - accuracy: 0.9865220/240 [==========================>...] - ETA: 1s - loss: 0.0501 - accuracy: 0.9868230/240 [===========================>..] - ETA: 0s - loss: 0.0490 - accuracy: 0.9871240/240 [==============================] - ETA: 0s - loss: 0.0479 - accuracy: 0.9874
Epoch 00004: val_loss improved from 0.53322 to 0.51719, saving model to model-lung.hdf5
240/240 [==============================] - 24s 99ms/sample - loss: 0.0479 - accuracy: 0.9874 - val_loss: 0.5172 - val_accuracy: 0.7541
Epoch 5/50
 10/240 [>.............................] - ETA: 0s - loss: 0.0223 - accuracy: 0.9938 20/240 [=>............................] - ETA: 9s - loss: 0.0213 - accuracy: 0.9940 30/240 [==>...........................] - ETA: 12s - loss: 0.0211 - accuracy: 0.9940 40/240 [====>.........................] - ETA: 12s - loss: 0.0217 - accuracy: 0.9937 50/240 [=====>........................] - ETA: 13s - loss: 0.0224 - accuracy: 0.9936 60/240 [======>.......................] - ETA: 13s - loss: 0.0337 - accuracy: 0.9914 70/240 [=======>......................] - ETA: 12s - loss: 0.0323 - accuracy: 0.9917 80/240 [=========>....................] - ETA: 12s - loss: 0.0397 - accuracy: 0.9899 90/240 [==========>...................] - ETA: 11s - loss: 0.0374 - accuracy: 0.9904100/240 [===========>..................] - ETA: 10s - loss: 0.0366 - accuracy: 0.9905110/240 [============>.................] - ETA: 10s - loss: 0.0350 - accuracy: 0.9909120/240 [==============>...............] - ETA: 9s - loss: 0.0335 - accuracy: 0.9913 130/240 [===============>..............] - ETA: 8s - loss: 0.0324 - accuracy: 0.9917140/240 [================>.............] - ETA: 8s - loss: 0.0316 - accuracy: 0.9918150/240 [=================>............] - ETA: 7s - loss: 0.0309 - accuracy: 0.9919160/240 [===================>..........] - ETA: 6s - loss: 0.0303 - accuracy: 0.9920170/240 [====================>.........] - ETA: 5s - loss: 0.0294 - accuracy: 0.9923180/240 [=====================>........] - ETA: 4s - loss: 0.0288 - accuracy: 0.9924190/240 [======================>.......] - ETA: 4s - loss: 0.0281 - accuracy: 0.9926200/240 [========================>.....] - ETA: 3s - loss: 0.0278 - accuracy: 0.9926210/240 [=========================>....] - ETA: 2s - loss: 0.0310 - accuracy: 0.9919220/240 [==========================>...] - ETA: 1s - loss: 0.0304 - accuracy: 0.9920230/240 [===========================>..] - ETA: 0s - loss: 0.0299 - accuracy: 0.9921240/240 [==============================] - ETA: 0s - loss: 0.0372 - accuracy: 0.9907
Epoch 00005: val_loss improved from 0.51719 to 0.03799, saving model to model-lung.hdf5
240/240 [==============================] - 24s 100ms/sample - loss: 0.0372 - accuracy: 0.9907 - val_loss: 0.0380 - val_accuracy: 0.9910
Epoch 6/50
 10/240 [>.............................] - ETA: 0s - loss: 0.1829 - accuracy: 0.9544 20/240 [=>............................] - ETA: 9s - loss: 0.1042 - accuracy: 0.9744 30/240 [==>...........................] - ETA: 12s - loss: 0.0914 - accuracy: 0.9759 40/240 [====>.........................] - ETA: 12s - loss: 0.0751 - accuracy: 0.9808 50/240 [=====>........................] - ETA: 13s - loss: 0.0666 - accuracy: 0.9831 60/240 [======>.......................] - ETA: 12s - loss: 0.0602 - accuracy: 0.9847 70/240 [=======>......................] - ETA: 12s - loss: 0.0559 - accuracy: 0.9855 80/240 [=========>....................] - ETA: 12s - loss: 0.0517 - accuracy: 0.9867 90/240 [==========>...................] - ETA: 11s - loss: 0.0494 - accuracy: 0.9872100/240 [===========>..................] - ETA: 10s - loss: 0.0462 - accuracy: 0.9880110/240 [============>.................] - ETA: 10s - loss: 0.0505 - accuracy: 0.9874120/240 [==============>...............] - ETA: 9s - loss: 0.0483 - accuracy: 0.9879 130/240 [===============>..............] - ETA: 8s - loss: 0.0461 - accuracy: 0.9885140/240 [================>.............] - ETA: 7s - loss: 0.0441 - accuracy: 0.9889150/240 [=================>............] - ETA: 7s - loss: 0.0424 - accuracy: 0.9893160/240 [===================>..........] - ETA: 6s - loss: 0.0413 - accuracy: 0.9895170/240 [====================>.........] - ETA: 5s - loss: 0.0400 - accuracy: 0.9898180/240 [=====================>........] - ETA: 4s - loss: 0.0387 - accuracy: 0.9901190/240 [======================>.......] - ETA: 4s - loss: 0.0420 - accuracy: 0.9894200/240 [========================>.....] - ETA: 3s - loss: 0.0407 - accuracy: 0.9897210/240 [=========================>....] - ETA: 2s - loss: 0.0396 - accuracy: 0.9900220/240 [==========================>...] - ETA: 1s - loss: 0.0386 - accuracy: 0.9902230/240 [===========================>..] - ETA: 0s - loss: 0.0377 - accuracy: 0.9904240/240 [==============================] - ETA: 0s - loss: 0.0371 - accuracy: 0.9905
Epoch 00006: val_loss did not improve from 0.03799
240/240 [==============================] - 21s 86ms/sample - loss: 0.0371 - accuracy: 0.9905 - val_loss: 0.1962 - val_accuracy: 0.9575
Epoch 7/50
 10/240 [>.............................] - ETA: 0s - loss: 0.1005 - accuracy: 0.9782 20/240 [=>............................] - ETA: 9s - loss: 0.0628 - accuracy: 0.9844 30/240 [==>...........................] - ETA: 12s - loss: 0.0477 - accuracy: 0.9879 40/240 [====>.........................] - ETA: 12s - loss: 0.0398 - accuracy: 0.9897 50/240 [=====>........................] - ETA: 13s - loss: 0.0349 - accuracy: 0.9909 60/240 [======>.......................] - ETA: 12s - loss: 0.0326 - accuracy: 0.9912 70/240 [=======>......................] - ETA: 12s - loss: 0.0311 - accuracy: 0.9914 80/240 [=========>....................] - ETA: 12s - loss: 0.0293 - accuracy: 0.9919 90/240 [==========>...................] - ETA: 11s - loss: 0.0278 - accuracy: 0.9923100/240 [===========>..................] - ETA: 10s - loss: 0.0461 - accuracy: 0.9886110/240 [============>.................] - ETA: 10s - loss: 0.0436 - accuracy: 0.9891120/240 [==============>...............] - ETA: 9s - loss: 0.0413 - accuracy: 0.9896 130/240 [===============>..............] - ETA: 8s - loss: 0.0394 - accuracy: 0.9901140/240 [================>.............] - ETA: 8s - loss: 0.0433 - accuracy: 0.9891150/240 [=================>............] - ETA: 7s - loss: 0.0416 - accuracy: 0.9895160/240 [===================>..........] - ETA: 6s - loss: 0.0438 - accuracy: 0.9889170/240 [====================>.........] - ETA: 5s - loss: 0.0428 - accuracy: 0.9892180/240 [=====================>........] - ETA: 4s - loss: 0.0418 - accuracy: 0.9894190/240 [======================>.......] - ETA: 4s - loss: 0.0407 - accuracy: 0.9897200/240 [========================>.....] - ETA: 3s - loss: 0.0395 - accuracy: 0.9900210/240 [=========================>....] - ETA: 2s - loss: 0.0386 - accuracy: 0.9902220/240 [==========================>...] - ETA: 1s - loss: 0.0380 - accuracy: 0.9902230/240 [===========================>..] - ETA: 0s - loss: 0.0372 - accuracy: 0.9904240/240 [==============================] - ETA: 0s - loss: 0.0365 - accuracy: 0.9906
Epoch 00007: val_loss did not improve from 0.03799
240/240 [==============================] - 21s 86ms/sample - loss: 0.0365 - accuracy: 0.9906 - val_loss: 0.0523 - val_accuracy: 0.9821
Epoch 8/50
 10/240 [>.............................] - ETA: 0s - loss: 0.0162 - accuracy: 0.9954 20/240 [=>............................] - ETA: 9s - loss: 0.0520 - accuracy: 0.9883 30/240 [==>...........................] - ETA: 12s - loss: 0.1005 - accuracy: 0.9779 40/240 [====>.........................] - ETA: 12s - loss: 0.1003 - accuracy: 0.9772 50/240 [=====>........................] - ETA: 13s - loss: 0.0838 - accuracy: 0.9808 60/240 [======>.......................] - ETA: 13s - loss: 0.0735 - accuracy: 0.9831 70/240 [=======>......................] - ETA: 12s - loss: 0.0655 - accuracy: 0.9848 80/240 [=========>....................] - ETA: 12s - loss: 0.0596 - accuracy: 0.9861 90/240 [==========>...................] - ETA: 11s - loss: 0.0548 - accuracy: 0.9872100/240 [===========>..................] - ETA: 10s - loss: 0.0511 - accuracy: 0.9880110/240 [============>.................] - ETA: 10s - loss: 0.0483 - accuracy: 0.9886120/240 [==============>...............] - ETA: 9s - loss: 0.0458 - accuracy: 0.9891 130/240 [===============>..............] - ETA: 8s - loss: 0.0440 - accuracy: 0.9896140/240 [================>.............] - ETA: 8s - loss: 0.0420 - accuracy: 0.9900150/240 [=================>............] - ETA: 7s - loss: 0.0403 - accuracy: 0.9903160/240 [===================>..........] - ETA: 6s - loss: 0.0389 - accuracy: 0.9906170/240 [====================>.........] - ETA: 5s - loss: 0.0375 - accuracy: 0.9909180/240 [=====================>........] - ETA: 4s - loss: 0.0363 - accuracy: 0.9912190/240 [======================>.......] - ETA: 4s - loss: 0.0352 - accuracy: 0.9914200/240 [========================>.....] - ETA: 3s - loss: 0.0343 - accuracy: 0.9916210/240 [=========================>....] - ETA: 2s - loss: 0.0334 - accuracy: 0.9918220/240 [==========================>...] - ETA: 1s - loss: 0.0326 - accuracy: 0.9920230/240 [===========================>..] - ETA: 0s - loss: 0.0318 - accuracy: 0.9922240/240 [==============================] - ETA: 0s - loss: 0.0343 - accuracy: 0.9916
Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.

Epoch 00008: val_loss did not improve from 0.03799
240/240 [==============================] - 26s 109ms/sample - loss: 0.0343 - accuracy: 0.9916 - val_loss: 0.0724 - val_accuracy: 0.9736
Epoch 9/50
 10/240 [>.............................] - ETA: 0s - loss: 0.0169 - accuracy: 0.9940 20/240 [=>............................] - ETA: 9s - loss: 0.0165 - accuracy: 0.9944 30/240 [==>...........................] - ETA: 12s - loss: 0.0444 - accuracy: 0.9889 40/240 [====>.........................] - ETA: 13s - loss: 0.0366 - accuracy: 0.9907 50/240 [=====>........................] - ETA: 13s - loss: 0.0321 - accuracy: 0.9916 60/240 [======>.......................] - ETA: 13s - loss: 0.0620 - accuracy: 0.9859 70/240 [=======>......................] - ETA: 12s - loss: 0.0551 - accuracy: 0.9874 80/240 [=========>....................] - ETA: 12s - loss: 0.0500 - accuracy: 0.9884 90/240 [==========>...................] - ETA: 11s - loss: 0.0458 - accuracy: 0.9893100/240 [===========>..................] - ETA: 10s - loss: 0.0430 - accuracy: 0.9899110/240 [============>.................] - ETA: 10s - loss: 0.0405 - accuracy: 0.9904120/240 [==============>...............] - ETA: 9s - loss: 0.0384 - accuracy: 0.9908 130/240 [===============>..............] - ETA: 8s - loss: 0.0366 - accuracy: 0.9912140/240 [================>.............] - ETA: 8s - loss: 0.0349 - accuracy: 0.9916150/240 [=================>............] - ETA: 7s - loss: 0.0334 - accuracy: 0.9919160/240 [===================>..........] - ETA: 6s - loss: 0.0323 - accuracy: 0.9921170/240 [====================>.........] - ETA: 5s - loss: 0.0313 - accuracy: 0.9923180/240 [=====================>........] - ETA: 4s - loss: 0.0306 - accuracy: 0.9925190/240 [======================>.......] - ETA: 4s - loss: 0.0300 - accuracy: 0.9926200/240 [========================>.....] - ETA: 3s - loss: 0.0292 - accuracy: 0.9928210/240 [=========================>....] - ETA: 2s - loss: 0.0319 - accuracy: 0.9923220/240 [==========================>...] - ETA: 1s - loss: 0.0344 - accuracy: 0.9917230/240 [===========================>..] - ETA: 0s - loss: 0.0336 - accuracy: 0.9919240/240 [==============================] - ETA: 0s - loss: 0.0329 - accuracy: 0.9920
Epoch 00009: val_loss improved from 0.03799 to 0.02843, saving model to model-lung.hdf5
240/240 [==============================] - 24s 101ms/sample - loss: 0.0329 - accuracy: 0.9920 - val_loss: 0.0284 - val_accuracy: 0.9902
Epoch 10/50
 10/240 [>.............................] - ETA: 0s - loss: 0.0131 - accuracy: 0.9962 20/240 [=>............................] - ETA: 9s - loss: 0.0505 - accuracy: 0.9877 30/240 [==>...........................] - ETA: 11s - loss: 0.0381 - accuracy: 0.9905 40/240 [====>.........................] - ETA: 12s - loss: 0.0319 - accuracy: 0.9920 50/240 [=====>........................] - ETA: 13s - loss: 0.0437 - accuracy: 0.9894 60/240 [======>.......................] - ETA: 12s - loss: 0.0392 - accuracy: 0.9904 70/240 [=======>......................] - ETA: 12s - loss: 0.0356 - accuracy: 0.9912 80/240 [=========>....................] - ETA: 12s - loss: 0.0328 - accuracy: 0.9918 90/240 [==========>...................] - ETA: 11s - loss: 0.0307 - accuracy: 0.9923100/240 [===========>..................] - ETA: 10s - loss: 0.0357 - accuracy: 0.9910110/240 [============>.................] - ETA: 10s - loss: 0.0337 - accuracy: 0.9915120/240 [==============>...............] - ETA: 9s - loss: 0.0321 - accuracy: 0.9919 130/240 [===============>..............] - ETA: 8s - loss: 0.0452 - accuracy: 0.9893140/240 [================>.............] - ETA: 8s - loss: 0.0430 - accuracy: 0.9897150/240 [=================>............] - ETA: 7s - loss: 0.0410 - accuracy: 0.9902160/240 [===================>..........] - ETA: 6s - loss: 0.0395 - accuracy: 0.9905170/240 [====================>.........] - ETA: 5s - loss: 0.0383 - accuracy: 0.9907180/240 [=====================>........] - ETA: 4s - loss: 0.0369 - accuracy: 0.9911190/240 [======================>.......] - ETA: 4s - loss: 0.0356 - accuracy: 0.9914200/240 [========================>.....] - ETA: 3s - loss: 0.0346 - accuracy: 0.9916210/240 [=========================>....] - ETA: 2s - loss: 0.0337 - accuracy: 0.9918220/240 [==========================>...] - ETA: 1s - loss: 0.0328 - accuracy: 0.9919230/240 [===========================>..] - ETA: 0s - loss: 0.0320 - accuracy: 0.9921240/240 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 0.9923
Epoch 00010: val_loss improved from 0.02843 to 0.02381, saving model to model-lung.hdf5
240/240 [==============================] - 24s 101ms/sample - loss: 0.0312 - accuracy: 0.9923 - val_loss: 0.0238 - val_accuracy: 0.9922
Epoch 11/50
 10/240 [>.............................] - ETA: 0s - loss: 0.0121 - accuracy: 0.9970 20/240 [=>............................] - ETA: 9s - loss: 0.0125 - accuracy: 0.9968 30/240 [==>...........................] - ETA: 12s - loss: 0.0130 - accuracy: 0.9965 40/240 [====>.........................] - ETA: 13s - loss: 0.0134 - accuracy: 0.9963 50/240 [=====>........................] - ETA: 13s - loss: 0.0135 - accuracy: 0.9963 60/240 [======>.......................] - ETA: 13s - loss: 0.0135 - accuracy: 0.9962 70/240 [=======>......................] - ETA: 12s - loss: 0.0139 - accuracy: 0.9962 80/240 [=========>....................] - ETA: 12s - loss: 0.0142 - accuracy: 0.9961 90/240 [==========>...................] - ETA: 11s - loss: 0.0142 - accuracy: 0.9961100/240 [===========>..................] - ETA: 10s - loss: 0.0143 - accuracy: 0.9960110/240 [============>.................] - ETA: 10s - loss: 0.0207 - accuracy: 0.9944120/240 [==============>...............] - ETA: 9s - loss: 0.0200 - accuracy: 0.9946 130/240 [===============>..............] - ETA: 8s - loss: 0.0197 - accuracy: 0.9946140/240 [================>.............] - ETA: 8s - loss: 0.0193 - accuracy: 0.9947150/240 [=================>............] - ETA: 7s - loss: 0.0190 - accuracy: 0.9948160/240 [===================>..........] - ETA: 6s - loss: 0.0188 - accuracy: 0.9949170/240 [====================>.........] - ETA: 5s - loss: 0.0187 - accuracy: 0.9949180/240 [=====================>........] - ETA: 4s - loss: 0.0184 - accuracy: 0.9949190/240 [======================>.......] - ETA: 4s - loss: 0.0182 - accuracy: 0.9950200/240 [========================>.....] - ETA: 3s - loss: 0.0179 - accuracy: 0.9951210/240 [=========================>....] - ETA: 2s - loss: 0.0214 - accuracy: 0.9945220/240 [==========================>...] - ETA: 1s - loss: 0.0286 - accuracy: 0.9928230/240 [===========================>..] - ETA: 0s - loss: 0.0280 - accuracy: 0.9930240/240 [==============================] - ETA: 0s - loss: 0.0303 - accuracy: 0.9923
Epoch 00011: val_loss improved from 0.02381 to 0.02050, saving model to model-lung.hdf5
240/240 [==============================] - 24s 101ms/sample - loss: 0.0303 - accuracy: 0.9923 - val_loss: 0.0205 - val_accuracy: 0.9938
Epoch 12/50
 10/240 [>.............................] - ETA: 0s - loss: 0.0993 - accuracy: 0.9820 20/240 [=>............................] - ETA: 9s - loss: 0.0565 - accuracy: 0.9892 30/240 [==>...........................] - ETA: 12s - loss: 0.0421 - accuracy: 0.9916 40/240 [====>.........................] - ETA: 13s - loss: 0.0350 - accuracy: 0.9927 50/240 [=====>........................] - ETA: 13s - loss: 0.0459 - accuracy: 0.9898 60/240 [======>.......................] - ETA: 12s - loss: 0.0406 - accuracy: 0.9909 70/240 [=======>......................] - ETA: 12s - loss: 0.0374 - accuracy: 0.9915 80/240 [=========>....................] - ETA: 12s - loss: 0.0345 - accuracy: 0.9921 90/240 [==========>...................] - ETA: 11s - loss: 0.0321 - accuracy: 0.9925100/240 [===========>..................] - ETA: 10s - loss: 0.0305 - accuracy: 0.9928110/240 [============>.................] - ETA: 10s - loss: 0.0294 - accuracy: 0.9930120/240 [==============>...............] - ETA: 9s - loss: 0.0281 - accuracy: 0.9933 130/240 [===============>..............] - ETA: 8s - loss: 0.0316 - accuracy: 0.9923140/240 [================>.............] - ETA: 8s - loss: 0.0303 - accuracy: 0.9926150/240 [=================>............] - ETA: 7s - loss: 0.0293 - accuracy: 0.9928160/240 [===================>..........] - ETA: 6s - loss: 0.0283 - accuracy: 0.9930170/240 [====================>.........] - ETA: 5s - loss: 0.0275 - accuracy: 0.9932180/240 [=====================>........] - ETA: 4s - loss: 0.0269 - accuracy: 0.9933190/240 [======================>.......] - ETA: 4s - loss: 0.0262 - accuracy: 0.9934200/240 [========================>.....] - ETA: 3s - loss: 0.0332 - accuracy: 0.9917210/240 [=========================>....] - ETA: 2s - loss: 0.0323 - accuracy: 0.9919220/240 [==========================>...] - ETA: 1s - loss: 0.0315 - accuracy: 0.9921230/240 [===========================>..] - ETA: 0s - loss: 0.0309 - accuracy: 0.9923240/240 [==============================] - ETA: 0s - loss: 0.0302 - accuracy: 0.9924
Epoch 00012: val_loss improved from 0.02050 to 0.01900, saving model to model-lung.hdf5
240/240 [==============================] - 24s 100ms/sample - loss: 0.0302 - accuracy: 0.9924 - val_loss: 0.0190 - val_accuracy: 0.9947
Epoch 13/50
 10/240 [>.............................] - ETA: 0s - loss: 0.0143 - accuracy: 0.9962 20/240 [=>............................] - ETA: 9s - loss: 0.0503 - accuracy: 0.9894 30/240 [==>...........................] - ETA: 12s - loss: 0.0603 - accuracy: 0.9855 40/240 [====>.........................] - ETA: 13s - loss: 0.0488 - accuracy: 0.9882 50/240 [=====>........................] - ETA: 13s - loss: 0.0420 - accuracy: 0.9898 60/240 [======>.......................] - ETA: 13s - loss: 0.0372 - accuracy: 0.9909 70/240 [=======>......................] - ETA: 12s - loss: 0.0340 - accuracy: 0.9917 80/240 [=========>....................] - ETA: 12s - loss: 0.0315 - accuracy: 0.9923 90/240 [==========>...................] - ETA: 11s - loss: 0.0297 - accuracy: 0.9927100/240 [===========>..................] - ETA: 10s - loss: 0.0282 - accuracy: 0.9930110/240 [============>.................] - ETA: 10s - loss: 0.0271 - accuracy: 0.9933120/240 [==============>...............] - ETA: 9s - loss: 0.0263 - accuracy: 0.9934 130/240 [===============>..............] - ETA: 8s - loss: 0.0254 - accuracy: 0.9936140/240 [================>.............] - ETA: 8s - loss: 0.0246 - accuracy: 0.9938150/240 [=================>............] - ETA: 7s - loss: 0.0240 - accuracy: 0.9940160/240 [===================>..........] - ETA: 6s - loss: 0.0234 - accuracy: 0.9941170/240 [====================>.........] - ETA: 5s - loss: 0.0230 - accuracy: 0.9942180/240 [=====================>........] - ETA: 4s - loss: 0.0224 - accuracy: 0.9943190/240 [======================>.......] - ETA: 4s - loss: 0.0307 - accuracy: 0.9924200/240 [========================>.....] - ETA: 3s - loss: 0.0298 - accuracy: 0.9926210/240 [=========================>....] - ETA: 2s - loss: 0.0291 - accuracy: 0.9928220/240 [==========================>...] - ETA: 1s - loss: 0.0284 - accuracy: 0.9930230/240 [===========================>..] - ETA: 0s - loss: 0.0296 - accuracy: 0.9926240/240 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 0.9926
Epoch 00013: val_loss did not improve from 0.01900
240/240 [==============================] - 21s 86ms/sample - loss: 0.0292 - accuracy: 0.9926 - val_loss: 0.0190 - val_accuracy: 0.9947
Epoch 14/50
 10/240 [>.............................] - ETA: 0s - loss: 0.0137 - accuracy: 0.9965 20/240 [=>............................] - ETA: 9s - loss: 0.0147 - accuracy: 0.9963 30/240 [==>...........................] - ETA: 12s - loss: 0.0148 - accuracy: 0.9962 40/240 [====>.........................] - ETA: 12s - loss: 0.0240 - accuracy: 0.9933 50/240 [=====>........................] - ETA: 13s - loss: 0.0220 - accuracy: 0.9939 60/240 [======>.......................] - ETA: 12s - loss: 0.0330 - accuracy: 0.9921 70/240 [=======>......................] - ETA: 12s - loss: 0.0305 - accuracy: 0.9926 80/240 [=========>....................] - ETA: 12s - loss: 0.0290 - accuracy: 0.9929 90/240 [==========>...................] - ETA: 11s - loss: 0.0274 - accuracy: 0.9933100/240 [===========>..................] - ETA: 10s - loss: 0.0262 - accuracy: 0.9936110/240 [============>.................] - ETA: 10s - loss: 0.0392 - accuracy: 0.9903120/240 [==============>...............] - ETA: 9s - loss: 0.0370 - accuracy: 0.9908 130/240 [===============>..............] - ETA: 8s - loss: 0.0399 - accuracy: 0.9900140/240 [================>.............] - ETA: 8s - loss: 0.0384 - accuracy: 0.9904150/240 [=================>............] - ETA: 7s - loss: 0.0368 - accuracy: 0.9908160/240 [===================>..........] - ETA: 6s - loss: 0.0355 - accuracy: 0.9911170/240 [====================>.........] - ETA: 5s - loss: 0.0344 - accuracy: 0.9914180/240 [=====================>........] - ETA: 4s - loss: 0.0333 - accuracy: 0.9917190/240 [======================>.......] - ETA: 4s - loss: 0.0322 - accuracy: 0.9920200/240 [========================>.....] - ETA: 3s - loss: 0.0314 - accuracy: 0.9921210/240 [=========================>....] - ETA: 2s - loss: 0.0306 - accuracy: 0.9923220/240 [==========================>...] - ETA: 1s - loss: 0.0303 - accuracy: 0.9924230/240 [===========================>..] - ETA: 0s - loss: 0.0297 - accuracy: 0.9925240/240 [==============================] - ETA: 0s - loss: 0.0291 - accuracy: 0.9927
Epoch 00014: val_loss improved from 0.01900 to 0.01863, saving model to model-lung.hdf5
240/240 [==============================] - 24s 100ms/sample - loss: 0.0291 - accuracy: 0.9927 - val_loss: 0.0186 - val_accuracy: 0.9951
Epoch 15/50
 10/240 [>.............................] - ETA: 0s - loss: 0.0130 - accuracy: 0.9966 20/240 [=>............................] - ETA: 9s - loss: 0.0146 - accuracy: 0.9963 30/240 [==>...........................] - ETA: 12s - loss: 0.0143 - accuracy: 0.9964 40/240 [====>.........................] - ETA: 12s - loss: 0.0534 - accuracy: 0.9866 50/240 [=====>........................] - ETA: 13s - loss: 0.0571 - accuracy: 0.9851 60/240 [======>.......................] - ETA: 12s - loss: 0.0501 - accuracy: 0.9870 70/240 [=======>......................] - ETA: 12s - loss: 0.0452 - accuracy: 0.9883 80/240 [=========>....................] - ETA: 12s - loss: 0.0417 - accuracy: 0.9893 90/240 [==========>...................] - ETA: 11s - loss: 0.0385 - accuracy: 0.9901100/240 [===========>..................] - ETA: 10s - loss: 0.0364 - accuracy: 0.9906110/240 [============>.................] - ETA: 10s - loss: 0.0345 - accuracy: 0.9911120/240 [==============>...............] - ETA: 9s - loss: 0.0389 - accuracy: 0.9904 130/240 [===============>..............] - ETA: 8s - loss: 0.0375 - accuracy: 0.9908140/240 [================>.............] - ETA: 8s - loss: 0.0359 - accuracy: 0.9911150/240 [=================>............] - ETA: 7s - loss: 0.0346 - accuracy: 0.9914160/240 [===================>..........] - ETA: 6s - loss: 0.0358 - accuracy: 0.9909170/240 [====================>.........] - ETA: 5s - loss: 0.0345 - accuracy: 0.9912180/240 [=====================>........] - ETA: 4s - loss: 0.0334 - accuracy: 0.9915190/240 [======================>.......] - ETA: 4s - loss: 0.0324 - accuracy: 0.9918200/240 [========================>.....] - ETA: 3s - loss: 0.0315 - accuracy: 0.9920210/240 [=========================>....] - ETA: 2s - loss: 0.0310 - accuracy: 0.9921220/240 [==========================>...] - ETA: 1s - loss: 0.0302 - accuracy: 0.9923230/240 [===========================>..] - ETA: 0s - loss: 0.0294 - accuracy: 0.9925240/240 [==============================] - ETA: 0s - loss: 0.0289 - accuracy: 0.9927
Epoch 00015: val_loss did not improve from 0.01863
240/240 [==============================] - 21s 86ms/sample - loss: 0.0289 - accuracy: 0.9927 - val_loss: 0.0187 - val_accuracy: 0.9952
Epoch 16/50
 10/240 [>.............................] - ETA: 0s - loss: 0.0140 - accuracy: 0.9964 20/240 [=>............................] - ETA: 9s - loss: 0.0152 - accuracy: 0.9961 30/240 [==>...........................] - ETA: 12s - loss: 0.0153 - accuracy: 0.9961 40/240 [====>.........................] - ETA: 12s - loss: 0.0318 - accuracy: 0.9927 50/240 [=====>........................] - ETA: 13s - loss: 0.0283 - accuracy: 0.9934 60/240 [======>.......................] - ETA: 12s - loss: 0.0262 - accuracy: 0.9938 70/240 [=======>......................] - ETA: 12s - loss: 0.0244 - accuracy: 0.9941 80/240 [=========>....................] - ETA: 12s - loss: 0.0233 - accuracy: 0.9943 90/240 [==========>...................] - ETA: 11s - loss: 0.0222 - accuracy: 0.9945100/240 [===========>..................] - ETA: 10s - loss: 0.0359 - accuracy: 0.9910110/240 [============>.................] - ETA: 10s - loss: 0.0339 - accuracy: 0.9915120/240 [==============>...............] - ETA: 9s - loss: 0.0325 - accuracy: 0.9918 130/240 [===============>..............] - ETA: 8s - loss: 0.0311 - accuracy: 0.9921140/240 [================>.............] - ETA: 8s - loss: 0.0297 - accuracy: 0.9925150/240 [=================>............] - ETA: 7s - loss: 0.0285 - accuracy: 0.9928160/240 [===================>..........] - ETA: 6s - loss: 0.0314 - accuracy: 0.9919170/240 [====================>.........] - ETA: 5s - loss: 0.0302 - accuracy: 0.9922180/240 [=====================>........] - ETA: 4s - loss: 0.0312 - accuracy: 0.9918190/240 [======================>.......] - ETA: 4s - loss: 0.0302 - accuracy: 0.9920200/240 [========================>.....] - ETA: 3s - loss: 0.0296 - accuracy: 0.9922210/240 [=========================>....] - ETA: 2s - loss: 0.0288 - accuracy: 0.9924220/240 [==========================>...] - ETA: 1s - loss: 0.0283 - accuracy: 0.9926230/240 [===========================>..] - ETA: 0s - loss: 0.0277 - accuracy: 0.9927240/240 [==============================] - ETA: 0s - loss: 0.0272 - accuracy: 0.9929
Epoch 00016: val_loss improved from 0.01863 to 0.01841, saving model to model-lung.hdf5
240/240 [==============================] - 24s 102ms/sample - loss: 0.0272 - accuracy: 0.9929 - val_loss: 0.0184 - val_accuracy: 0.9953
Epoch 17/50
 10/240 [>.............................] - ETA: 0s - loss: 0.0140 - accuracy: 0.9959 20/240 [=>............................] - ETA: 9s - loss: 0.0145 - accuracy: 0.9960 30/240 [==>...........................] - ETA: 12s - loss: 0.0144 - accuracy: 0.9961 40/240 [====>.........................] - ETA: 13s - loss: 0.0142 - accuracy: 0.9962 50/240 [=====>........................] - ETA: 13s - loss: 0.0138 - accuracy: 0.9964 60/240 [======>.......................] - ETA: 13s - loss: 0.0141 - accuracy: 0.9963 70/240 [=======>......................] - ETA: 12s - loss: 0.0146 - accuracy: 0.9962 80/240 [=========>....................] - ETA: 12s - loss: 0.0144 - accuracy: 0.9962 90/240 [==========>...................] - ETA: 11s - loss: 0.0226 - accuracy: 0.9947100/240 [===========>..................] - ETA: 11s - loss: 0.0218 - accuracy: 0.9948110/240 [============>.................] - ETA: 10s - loss: 0.0339 - accuracy: 0.9915120/240 [==============>...............] - ETA: 9s - loss: 0.0323 - accuracy: 0.9919 130/240 [===============>..............] - ETA: 8s - loss: 0.0353 - accuracy: 0.9909140/240 [================>.............] - ETA: 8s - loss: 0.0337 - accuracy: 0.9913150/240 [=================>............] - ETA: 7s - loss: 0.0323 - accuracy: 0.9916160/240 [===================>..........] - ETA: 6s - loss: 0.0311 - accuracy: 0.9920170/240 [====================>.........] - ETA: 5s - loss: 0.0302 - accuracy: 0.9922180/240 [=====================>........] - ETA: 4s - loss: 0.0292 - accuracy: 0.9925190/240 [======================>.......] - ETA: 4s - loss: 0.0284 - accuracy: 0.9927200/240 [========================>.....] - ETA: 3s - loss: 0.0291 - accuracy: 0.9923210/240 [=========================>....] - ETA: 2s - loss: 0.0285 - accuracy: 0.9925220/240 [==========================>...] - ETA: 1s - loss: 0.0279 - accuracy: 0.9927230/240 [===========================>..] - ETA: 0s - loss: 0.0275 - accuracy: 0.9928240/240 [==============================] - ETA: 0s - loss: 0.0270 - accuracy: 0.9930
Epoch 00017: val_loss did not improve from 0.01841
240/240 [==============================] - 21s 87ms/sample - loss: 0.0270 - accuracy: 0.9930 - val_loss: 0.0185 - val_accuracy: 0.9952
Epoch 18/50
 10/240 [>.............................] - ETA: 0s - loss: 0.0840 - accuracy: 0.9820 20/240 [=>............................] - ETA: 9s - loss: 0.0492 - accuracy: 0.9891 30/240 [==>...........................] - ETA: 12s - loss: 0.0373 - accuracy: 0.9915 40/240 [====>.........................] - ETA: 13s - loss: 0.0328 - accuracy: 0.9925 50/240 [=====>........................] - ETA: 13s - loss: 0.0290 - accuracy: 0.9932 60/240 [======>.......................] - ETA: 13s - loss: 0.0265 - accuracy: 0.9937 70/240 [=======>......................] - ETA: 12s - loss: 0.0320 - accuracy: 0.9917 80/240 [=========>....................] - ETA: 12s - loss: 0.0296 - accuracy: 0.9922 90/240 [==========>...................] - ETA: 11s - loss: 0.0276 - accuracy: 0.9927100/240 [===========>..................] - ETA: 10s - loss: 0.0264 - accuracy: 0.9931110/240 [============>.................] - ETA: 10s - loss: 0.0251 - accuracy: 0.9934120/240 [==============>...............] - ETA: 9s - loss: 0.0243 - accuracy: 0.9936 130/240 [===============>..............] - ETA: 8s - loss: 0.0346 - accuracy: 0.9909140/240 [================>.............] - ETA: 8s - loss: 0.0352 - accuracy: 0.9906150/240 [=================>............] - ETA: 7s - loss: 0.0336 - accuracy: 0.9910160/240 [===================>..........] - ETA: 6s - loss: 0.0322 - accuracy: 0.9914170/240 [====================>.........] - ETA: 5s - loss: 0.0311 - accuracy: 0.9917180/240 [=====================>........] - ETA: 4s - loss: 0.0304 - accuracy: 0.9919190/240 [======================>.......] - ETA: 4s - loss: 0.0298 - accuracy: 0.9921200/240 [========================>.....] - ETA: 3s - loss: 0.0292 - accuracy: 0.9923210/240 [=========================>....] - ETA: 2s - loss: 0.0286 - accuracy: 0.9924220/240 [==========================>...] - ETA: 1s - loss: 0.0280 - accuracy: 0.9926230/240 [===========================>..] - ETA: 0s - loss: 0.0274 - accuracy: 0.9927240/240 [==============================] - ETA: 0s - loss: 0.0269 - accuracy: 0.9929
Epoch 00018: val_loss improved from 0.01841 to 0.01841, saving model to model-lung.hdf5
240/240 [==============================] - 24s 101ms/sample - loss: 0.0269 - accuracy: 0.9929 - val_loss: 0.0184 - val_accuracy: 0.9952
Epoch 19/50
 10/240 [>.............................] - ETA: 0s - loss: 0.0150 - accuracy: 0.9968 20/240 [=>............................] - ETA: 9s - loss: 0.0150 - accuracy: 0.9964 30/240 [==>...........................] - ETA: 12s - loss: 0.0144 - accuracy: 0.9966 40/240 [====>.........................] - ETA: 13s - loss: 0.0142 - accuracy: 0.9965 50/240 [=====>........................] - ETA: 13s - loss: 0.0143 - accuracy: 0.9964 60/240 [======>.......................] - ETA: 12s - loss: 0.0272 - accuracy: 0.9941 70/240 [=======>......................] - ETA: 12s - loss: 0.0257 - accuracy: 0.9943 80/240 [=========>....................] - ETA: 12s - loss: 0.0240 - accuracy: 0.9946 90/240 [==========>...................] - ETA: 11s - loss: 0.0269 - accuracy: 0.9935100/240 [===========>..................] - ETA: 10s - loss: 0.0256 - accuracy: 0.9937110/240 [============>.................] - ETA: 10s - loss: 0.0245 - accuracy: 0.9940120/240 [==============>...............] - ETA: 9s - loss: 0.0237 - accuracy: 0.9941 130/240 [===============>..............] - ETA: 8s - loss: 0.0230 - accuracy: 0.9943140/240 [================>.............] - ETA: 8s - loss: 0.0223 - accuracy: 0.9944150/240 [=================>............] - ETA: 7s - loss: 0.0216 - accuracy: 0.9945160/240 [===================>..........] - ETA: 6s - loss: 0.0211 - accuracy: 0.9946170/240 [====================>.........] - ETA: 5s - loss: 0.0210 - accuracy: 0.9946180/240 [=====================>........] - ETA: 4s - loss: 0.0205 - accuracy: 0.9948190/240 [======================>.......] - ETA: 4s - loss: 0.0201 - accuracy: 0.9949200/240 [========================>.....] - ETA: 3s - loss: 0.0263 - accuracy: 0.9931210/240 [=========================>....] - ETA: 2s - loss: 0.0283 - accuracy: 0.9925220/240 [==========================>...] - ETA: 1s - loss: 0.0276 - accuracy: 0.9927230/240 [===========================>..] - ETA: 0s - loss: 0.0270 - accuracy: 0.9928240/240 [==============================] - ETA: 0s - loss: 0.0264 - accuracy: 0.9930
Epoch 00019: val_loss improved from 0.01841 to 0.01801, saving model to model-lung.hdf5
240/240 [==============================] - 24s 99ms/sample - loss: 0.0264 - accuracy: 0.9930 - val_loss: 0.0180 - val_accuracy: 0.9952
Epoch 20/50
 10/240 [>.............................] - ETA: 0s - loss: 0.0124 - accuracy: 0.9967 20/240 [=>............................] - ETA: 9s - loss: 0.0148 - accuracy: 0.9961 30/240 [==>...........................] - ETA: 12s - loss: 0.0222 - accuracy: 0.9933 40/240 [====>.........................] - ETA: 13s - loss: 0.0529 - accuracy: 0.9851 50/240 [=====>........................] - ETA: 13s - loss: 0.0458 - accuracy: 0.9872 60/240 [======>.......................] - ETA: 13s - loss: 0.0407 - accuracy: 0.9886 70/240 [=======>......................] - ETA: 12s - loss: 0.0374 - accuracy: 0.9897 80/240 [=========>....................] - ETA: 12s - loss: 0.0346 - accuracy: 0.9906 90/240 [==========>...................] - ETA: 11s - loss: 0.0322 - accuracy: 0.9913100/240 [===========>..................] - ETA: 10s - loss: 0.0307 - accuracy: 0.9918110/240 [============>.................] - ETA: 10s - loss: 0.0296 - accuracy: 0.9921120/240 [==============>...............] - ETA: 9s - loss: 0.0312 - accuracy: 0.9911 130/240 [===============>..............] - ETA: 8s - loss: 0.0301 - accuracy: 0.9915140/240 [================>.............] - ETA: 8s - loss: 0.0291 - accuracy: 0.9918150/240 [=================>............] - ETA: 7s - loss: 0.0282 - accuracy: 0.9921160/240 [===================>..........] - ETA: 6s - loss: 0.0275 - accuracy: 0.9924170/240 [====================>.........] - ETA: 5s - loss: 0.0268 - accuracy: 0.9926180/240 [=====================>........] - ETA: 4s - loss: 0.0304 - accuracy: 0.9920190/240 [======================>.......] - ETA: 4s - loss: 0.0295 - accuracy: 0.9923200/240 [========================>.....] - ETA: 3s - loss: 0.0287 - accuracy: 0.9925210/240 [=========================>....] - ETA: 2s - loss: 0.0280 - accuracy: 0.9927220/240 [==========================>...] - ETA: 1s - loss: 0.0274 - accuracy: 0.9928230/240 [===========================>..] - ETA: 0s - loss: 0.0269 - accuracy: 0.9930240/240 [==============================] - ETA: 0s - loss: 0.0264 - accuracy: 0.9931
Epoch 00020: val_loss improved from 0.01801 to 0.01705, saving model to model-lung.hdf5
240/240 [==============================] - 24s 99ms/sample - loss: 0.0264 - accuracy: 0.9931 - val_loss: 0.0170 - val_accuracy: 0.9951
Epoch 21/50
 10/240 [>.............................] - ETA: 0s - loss: 0.0123 - accuracy: 0.9970 20/240 [=>............................] - ETA: 9s - loss: 0.0127 - accuracy: 0.9966 30/240 [==>...........................] - ETA: 12s - loss: 0.0199 - accuracy: 0.9940 40/240 [====>.........................] - ETA: 12s - loss: 0.0314 - accuracy: 0.9904 50/240 [=====>........................] - ETA: 13s - loss: 0.0289 - accuracy: 0.9914 60/240 [======>.......................] - ETA: 12s - loss: 0.0263 - accuracy: 0.9922 70/240 [=======>......................] - ETA: 12s - loss: 0.0241 - accuracy: 0.9929 80/240 [=========>....................] - ETA: 12s - loss: 0.0228 - accuracy: 0.9933 90/240 [==========>...................] - ETA: 11s - loss: 0.0215 - accuracy: 0.9937100/240 [===========>..................] - ETA: 10s - loss: 0.0207 - accuracy: 0.9939110/240 [============>.................] - ETA: 10s - loss: 0.0328 - accuracy: 0.9909120/240 [==============>...............] - ETA: 9s - loss: 0.0314 - accuracy: 0.9913 130/240 [===============>..............] - ETA: 8s - loss: 0.0300 - accuracy: 0.9917140/240 [================>.............] - ETA: 8s - loss: 0.0288 - accuracy: 0.9920150/240 [=================>............] - ETA: 7s - loss: 0.0276 - accuracy: 0.9923160/240 [===================>..........] - ETA: 6s - loss: 0.0268 - accuracy: 0.9926170/240 [====================>.........] - ETA: 5s - loss: 0.0260 - accuracy: 0.9928180/240 [=====================>........] - ETA: 4s - loss: 0.0253 - accuracy: 0.9930190/240 [======================>.......] - ETA: 4s - loss: 0.0246 - accuracy: 0.9932200/240 [========================>.....] - ETA: 3s - loss: 0.0240 - accuracy: 0.9934210/240 [=========================>....] - ETA: 2s - loss: 0.0270 - accuracy: 0.9929220/240 [==========================>...] - ETA: 1s - loss: 0.0264 - accuracy: 0.9930230/240 [===========================>..] - ETA: 0s - loss: 0.0258 - accuracy: 0.9931240/240 [==============================] - ETA: 0s - loss: 0.0254 - accuracy: 0.9933
Epoch 00021: val_loss did not improve from 0.01705
240/240 [==============================] - 21s 87ms/sample - loss: 0.0254 - accuracy: 0.9933 - val_loss: 0.0172 - val_accuracy: 0.9952
Epoch 22/50
 10/240 [>.............................] - ETA: 0s - loss: 0.0116 - accuracy: 0.9969 20/240 [=>............................] - ETA: 9s - loss: 0.0130 - accuracy: 0.9965 30/240 [==>...........................] - ETA: 12s - loss: 0.0132 - accuracy: 0.9963 40/240 [====>.........................] - ETA: 13s - loss: 0.0184 - accuracy: 0.9946 50/240 [=====>........................] - ETA: 13s - loss: 0.0172 - accuracy: 0.9950 60/240 [======>.......................] - ETA: 13s - loss: 0.0162 - accuracy: 0.9953 70/240 [=======>......................] - ETA: 12s - loss: 0.0154 - accuracy: 0.9956 80/240 [=========>....................] - ETA: 12s - loss: 0.0154 - accuracy: 0.9956 90/240 [==========>...................] - ETA: 11s - loss: 0.0149 - accuracy: 0.9958100/240 [===========>..................] - ETA: 11s - loss: 0.0149 - accuracy: 0.9958110/240 [============>.................] - ETA: 10s - loss: 0.0151 - accuracy: 0.9958120/240 [==============>...............] - ETA: 9s - loss: 0.0149 - accuracy: 0.9958 130/240 [===============>..............] - ETA: 8s - loss: 0.0211 - accuracy: 0.9948140/240 [================>.............] - ETA: 8s - loss: 0.0204 - accuracy: 0.9950150/240 [=================>............] - ETA: 7s - loss: 0.0266 - accuracy: 0.9931160/240 [===================>..........] - ETA: 6s - loss: 0.0256 - accuracy: 0.9934170/240 [====================>.........] - ETA: 5s - loss: 0.0248 - accuracy: 0.9936180/240 [=====================>........] - ETA: 4s - loss: 0.0272 - accuracy: 0.9928190/240 [======================>.......] - ETA: 4s - loss: 0.0264 - accuracy: 0.9930200/240 [========================>.....] - ETA: 3s - loss: 0.0257 - accuracy: 0.9932210/240 [=========================>....] - ETA: 2s - loss: 0.0251 - accuracy: 0.9933220/240 [==========================>...] - ETA: 1s - loss: 0.0248 - accuracy: 0.9934230/240 [===========================>..] - ETA: 0s - loss: 0.0242 - accuracy: 0.9936240/240 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 0.9937
Epoch 00022: val_loss did not improve from 0.01705
240/240 [==============================] - 21s 87ms/sample - loss: 0.0238 - accuracy: 0.9937 - val_loss: 0.0185 - val_accuracy: 0.9950
Epoch 23/50
 10/240 [>.............................] - ETA: 0s - loss: 0.0132 - accuracy: 0.9964 20/240 [=>............................] - ETA: 9s - loss: 0.0130 - accuracy: 0.9964 30/240 [==>...........................] - ETA: 12s - loss: 0.0144 - accuracy: 0.9960 40/240 [====>.........................] - ETA: 13s - loss: 0.0138 - accuracy: 0.9962 50/240 [=====>........................] - ETA: 13s - loss: 0.0305 - accuracy: 0.9909 60/240 [======>.......................] - ETA: 13s - loss: 0.0275 - accuracy: 0.9919 70/240 [=======>......................] - ETA: 12s - loss: 0.0354 - accuracy: 0.9907 80/240 [=========>....................] - ETA: 12s - loss: 0.0328 - accuracy: 0.9913 90/240 [==========>...................] - ETA: 11s - loss: 0.0307 - accuracy: 0.9919100/240 [===========>..................] - ETA: 10s - loss: 0.0294 - accuracy: 0.9922110/240 [============>.................] - ETA: 10s - loss: 0.0281 - accuracy: 0.9925120/240 [==============>...............] - ETA: 9s - loss: 0.0270 - accuracy: 0.9928 130/240 [===============>..............] - ETA: 8s - loss: 0.0262 - accuracy: 0.9931140/240 [================>.............] - ETA: 8s - loss: 0.0273 - accuracy: 0.9926150/240 [=================>............] - ETA: 7s - loss: 0.0264 - accuracy: 0.9928160/240 [===================>..........] - ETA: 6s - loss: 0.0268 - accuracy: 0.9926170/240 [====================>.........] - ETA: 5s - loss: 0.0260 - accuracy: 0.9928180/240 [=====================>........] - ETA: 4s - loss: 0.0256 - accuracy: 0.9929190/240 [======================>.......] - ETA: 4s - loss: 0.0249 - accuracy: 0.9931200/240 [========================>.....] - ETA: 3s - loss: 0.0244 - accuracy: 0.9932210/240 [=========================>....] - ETA: 2s - loss: 0.0238 - accuracy: 0.9934220/240 [==========================>...] - ETA: 1s - loss: 0.0234 - accuracy: 0.9935230/240 [===========================>..] - ETA: 0s - loss: 0.0229 - accuracy: 0.9936240/240 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 0.9938
Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.

Epoch 00023: val_loss did not improve from 0.01705
240/240 [==============================] - 21s 87ms/sample - loss: 0.0225 - accuracy: 0.9938 - val_loss: 0.0175 - val_accuracy: 0.9951
Epoch 24/50
 10/240 [>.............................] - ETA: 0s - loss: 0.0157 - accuracy: 0.9960 20/240 [=>............................] - ETA: 9s - loss: 0.0142 - accuracy: 0.9963 30/240 [==>...........................] - ETA: 12s - loss: 0.0139 - accuracy: 0.9963 40/240 [====>.........................] - ETA: 13s - loss: 0.0132 - accuracy: 0.9964 50/240 [=====>........................] - ETA: 13s - loss: 0.0136 - accuracy: 0.9964 60/240 [======>.......................] - ETA: 13s - loss: 0.0134 - accuracy: 0.9964 70/240 [=======>......................] - ETA: 12s - loss: 0.0131 - accuracy: 0.9965 80/240 [=========>....................] - ETA: 12s - loss: 0.0129 - accuracy: 0.9965 90/240 [==========>...................] - ETA: 11s - loss: 0.0129 - accuracy: 0.9965100/240 [===========>..................] - ETA: 10s - loss: 0.0127 - accuracy: 0.9965110/240 [============>.................] - ETA: 10s - loss: 0.0293 - accuracy: 0.9931120/240 [==============>...............] - ETA: 9s - loss: 0.0281 - accuracy: 0.9934 130/240 [===============>..............] - ETA: 8s - loss: 0.0283 - accuracy: 0.9931140/240 [================>.............] - ETA: 8s - loss: 0.0289 - accuracy: 0.9928150/240 [=================>............] - ETA: 7s - loss: 0.0278 - accuracy: 0.9931160/240 [===================>..........] - ETA: 6s - loss: 0.0267 - accuracy: 0.9933170/240 [====================>.........] - ETA: 5s - loss: 0.0259 - accuracy: 0.9935180/240 [=====================>........] - ETA: 4s - loss: 0.0252 - accuracy: 0.9936190/240 [======================>.......] - ETA: 4s - loss: 0.0246 - accuracy: 0.9938200/240 [========================>.....] - ETA: 3s - loss: 0.0273 - accuracy: 0.9932210/240 [=========================>....] - ETA: 2s - loss: 0.0266 - accuracy: 0.9934220/240 [==========================>...] - ETA: 1s - loss: 0.0259 - accuracy: 0.9936230/240 [===========================>..] - ETA: 0s - loss: 0.0253 - accuracy: 0.9937240/240 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 0.9938
Epoch 00024: val_loss did not improve from 0.01705
240/240 [==============================] - 21s 86ms/sample - loss: 0.0248 - accuracy: 0.9938 - val_loss: 0.0175 - val_accuracy: 0.9950
Epoch 25/50
 10/240 [>.............................] - ETA: 0s - loss: 0.0115 - accuracy: 0.9969 20/240 [=>............................] - ETA: 9s - loss: 0.0124 - accuracy: 0.9964 30/240 [==>...........................] - ETA: 12s - loss: 0.0194 - accuracy: 0.9942 40/240 [====>.........................] - ETA: 13s - loss: 0.0178 - accuracy: 0.9947 50/240 [=====>........................] - ETA: 13s - loss: 0.0168 - accuracy: 0.9950 60/240 [======>.......................] - ETA: 13s - loss: 0.0161 - accuracy: 0.9953 70/240 [=======>......................] - ETA: 12s - loss: 0.0154 - accuracy: 0.9955 80/240 [=========>....................] - ETA: 12s - loss: 0.0151 - accuracy: 0.9957 90/240 [==========>...................] - ETA: 11s - loss: 0.0147 - accuracy: 0.9958100/240 [===========>..................] - ETA: 11s - loss: 0.0252 - accuracy: 0.9926110/240 [============>.................] - ETA: 10s - loss: 0.0240 - accuracy: 0.9930120/240 [==============>...............] - ETA: 9s - loss: 0.0289 - accuracy: 0.9921 130/240 [===============>..............] - ETA: 8s - loss: 0.0276 - accuracy: 0.9925140/240 [================>.............] - ETA: 8s - loss: 0.0264 - accuracy: 0.9928150/240 [=================>............] - ETA: 7s - loss: 0.0258 - accuracy: 0.9930160/240 [===================>..........] - ETA: 6s - loss: 0.0250 - accuracy: 0.9932170/240 [====================>.........] - ETA: 5s - loss: 0.0241 - accuracy: 0.9934180/240 [=====================>........] - ETA: 4s - loss: 0.0234 - accuracy: 0.9936190/240 [======================>.......] - ETA: 4s - loss: 0.0229 - accuracy: 0.9938200/240 [========================>.....] - ETA: 3s - loss: 0.0225 - accuracy: 0.9939210/240 [=========================>....] - ETA: 2s - loss: 0.0220 - accuracy: 0.9940220/240 [==========================>...] - ETA: 1s - loss: 0.0215 - accuracy: 0.9942230/240 [===========================>..] - ETA: 0s - loss: 0.0221 - accuracy: 0.9939240/240 [==============================] - ETA: 0s - loss: 0.0217 - accuracy: 0.9940
Epoch 00025: val_loss did not improve from 0.01705
240/240 [==============================] - 21s 86ms/sample - loss: 0.0217 - accuracy: 0.9940 - val_loss: 0.0181 - val_accuracy: 0.9949
Epoch 00025: early stopping
